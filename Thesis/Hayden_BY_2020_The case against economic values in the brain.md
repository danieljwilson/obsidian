	# Info
**Title**: The case against economic values in the brain
**Journal**: Preprint
**Year**: 2020
**Authors**: [[Benjamin Y. Hayden]], [[Yael Niv]]

**Link**: [paperpile](chrome-extension://bomfdkbfpdhijjbeoicnfhjbdhncfhig/view.html?mp=UUPBtOaP)
**Tags**: #paper
**Rating**: #2star 

---
**Connections**:
[[lab meetings]]
[[value]]
[[neuroeconomics]]
[[brain]]
[[subjective value]]
[[behavioral economics]]
[[heuristics]]
[[choice]]
[[decision making]]
[[expected utiliity theory]]
[[eliminative materialism]]

# Notes
## Summary
##### Topline idea
Is it possible that "[[value]]", as conceptualized in [[neuroeconomics]], is **not**, in fact, represented in the brain?

**Instead** we explore idea that brains directly learn [[action policy|action policies]].

---

**[[neuroeconomics|Neuroeconomics]] assumptions**
- choices between options rely on an explicit **valuation process**
	- i.e. brain assigns values to each option and then chooses among
- [[value]] is a single **scalar** quantity
- [[common currency]] concept
	- valuation applies not just to goods but also effort costs, time delays, etc.
- that there are **neurons** or **brain regions** which have the distinct purpose of **encoding value**.

**[[reinforcement learning|RL]]**
- also driven by scalar values
- value of an option (state or action) = sum of expected future rewards (contingent on making that choice)

---

**View of economists**: Decision makers behave **as if** we compute and compare values (Friedman, 1953)
**View of neuroeconomists**: These **as if** theories are instantiated in the brain.

---

Brain areas commonly associated with value:
- [[ventromedial prefrontal cortex]]
- [[ventral striatum]]
- [[orbitofrontal cortex]]

These areas [[correlation|correlate]] with value, but so do other things (attention, action plans, vigor (O'Doherty, 2014))

---

**Some of the main issues**

- It is hard to get accurate measures of subjective value

- It is also hard to try and find neural correlates of these values. 
	- The problem is you need to **regress out all confounding variables**
	- any variable that influences choice will necessarily be correlated with value

- Impossible to disentangle preference and value as there is no way of measuring the divergence. This is known as the [[neuroeconomic relativity problem]]

---

Principle of common currency does not always hold in brain studies. 
- most findings support an encoding that depends on alternatives (==this seems more like preference than value==)

---

[[actor-critic model]] is proposed
==values are required to GET to deterministic policy...==


## Thoughts
>not all reinforcement learning algorithms rely on or even calculate values 
(Sutton & Barto, 2018)

Example?

---
>many empirically-supported process models of choice get by 
with no valuation (Vlaev et al., 2011; Miller et al., 2019; Gigerenzer and Gaissmaier, 2011)

What does this mean in practice?

---

>we may make this judgment without consulting an internal value signal

Not sure how to think of this outside of valuation??

---

>when choosing between and orange and a car it is immediately clear that one is better than the other without calculating the precise value of either

But is the argument that we don't do **precise** valuation or value at all? There are still values being consulted, no?

---

>Values may only be necessary when choosing between two very similarly valued items, at which point the brain may decide to choose randomly, according to some value-free heuristic.

Again doesn't the author mean **precise** values? And heuristics are not random. Nor are they generally, as I understand them, value-free. Just value simplifying. [[take the best heuristic]] for example. Maybe [[recognition heuristic]] but isn't value baked into this? If you recognize it it hasn't killed you in the most dire form...

---

Why is [[St. Petersburg Paradox]] a paradox? Isn't it just a matter of approaching it from the correct measure of central tendency? i.e. mode instead of mean?

---

In reference to the [[priority heuristic]] and how it explains many paradoxes of choice:

>all without ever requiring computing of value

But you **are** computing value along the chosen dimension?! It is about simplifying computation...not avoiding value calculation entirely

---

>the success of heuristic approaches demonstrates that value calculations are not *a priori* essential for neuroeconomic theories of choice.

But are we talking about value or calculation?? And there is still calculation in the sense of comparing the individual values. Just a simplification.

---

Like the bees as real world DDM...n option DDM ;)

---

On **value** and **subjective preference**
>One might interpret this finding as reflecting simple range adaptation of neurons that have a finite firing rate; however, a more parsimonious explanation is that the firing pattern is consistent with a relative preference code rather than an abstract value code. This interpretation places the putative neural representation of value one stage later than we would expect from a common-currency code – immediately after comparison (because a relative valuation is itself a comparison) rather than as an input to comparison. Importantly, with a code that depends on alternatives, there is no real sense in which we can read out the “true subjective value” of an option. We can only know if an option’s value is higher than another value – similar to the information provided by preferences and choice behavior. 

---

>it is unclear to what extent we can read out a meaningful value signal when only one option is available

Has Cendri run the food fMRI where subjects just looked at the items with no task and seen if there is a brain airea that correlates with self-report value?

Does it make sense to separate value from context?

---

>Behavior, as well as neural signals corresponding to prediction errors in the basal ganglia suggested that subjects were updating both options in opposite directions, learning relative choice propensities (a policy) rather than tracking the expected value of each option.

How could you learn a policy without value?

---

Idea is that once we have habitual choice strategies we no longer perform the calculations we used to develop those strategies



# Resources
