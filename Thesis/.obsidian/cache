{"files":{"Input/Matthew Botvinick - Meta-learning in brains and machines.md":{"mtime":1595527007139.619,"size":1412,"hash":"c3a591955aed6b56a6042a536a9efff5a8aae819a5cad4c945b76de1aab9c077"},"Input/meta-learning.md":{"mtime":1593886020842.7483,"size":22,"hash":"fd8a676776cc1885281cd316c5a451e3191d9581fca05816e07b96b2ecabfe86"},"Templates/Paper template.md":{"mtime":1594946773411.0208,"size":157,"hash":"3b6bde5694f31ac3bc688c977cdb369fd77d0c8c71f5a53685ea01aa14dd9d2c"},"Input/Roberts_I_2020_preprint.md":{"mtime":1594511323459.5461,"size":1959,"hash":"eb80fca0a8e871bb20dde6576bec37a7b35361ae60478e6a55c67346e9d6932b"},"Tips.md":{"mtime":1594510996437.7803,"size":41,"hash":"37558d452555f1e9ea676ca7dbc4db1aaf8f0fab1b848f0bb4de8ec12200f184"},"PKM.md":{"mtime":1594510727967.8757,"size":14,"hash":"6b0963b03e35ed281e2898fa8b6beae36f8685c63a257965f936ddd5c5cbbf75"},"Obsidian.md":{"mtime":1594510754210.3718,"size":27,"hash":"2be28d55974ca863bce6a7c1803cb352a48c7cf3cb36d0c1520be2692db2b8dd"},"Hause Tips for Obsidian.md":{"mtime":1594511849225.484,"size":62,"hash":"3bea295b17a13205b66cc0f48987d96a41f2fbb588dc83f0d1c09f46cf234236"},"Technology.md":{"mtime":1594651087178.9194,"size":0,"hash":"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"},"Cosine tuning model.md":{"mtime":1595031969994.8428,"size":449,"hash":"6ba62326215ae120408dd81a2ec779a32b0086110ae1df89f6b7e156ee92aee1"},"Hodkin & Huxley model.md":{"mtime":1595031970029.58,"size":147,"hash":"8bb4a46172ce52d59dab26358ab09886c8c1c2df4450a2086c742b2c70df5a02"},"Attachments/Pasted image.png":{"mtime":1594651944824.2012,"size":1683628,"hash":"750e462b2c108607ea0fe4592eec77ec8f02d73338f9a99b702caf3311250af6"},"Shadlen_MN_2001.md":{"mtime":1595527007165.4023,"size":393,"hash":"0a6b395e9750b3c0146f3faf1dcd50c6bb048e477b6924eba799ded5c885ccf1"},"Occam's Razor.md":{"mtime":1594849807319.9246,"size":84,"hash":"5d8917a9c44a9cc7ed59b39a2accdf97a3001ab6ac6f366a6cd3c39dd2a7f829"},"Levels of Analysis.md":{"mtime":1594849807375.4387,"size":166,"hash":"24c3232c7639311654dfb01e32ec2cad06b2f3e438b07b95b9b8ff3a92a00e31"},"Neuromatch.md":{"mtime":1595031970102.1091,"size":180,"hash":"7fd5efcd42728f471966a8dca3d3a2684c1b5b1a859caadf0a071ab4941adaa7"},"Pod People.md":{"mtime":1594663383697.417,"size":612,"hash":"b4c7407e6cf03ca6211552bed047ea54b447d8c993d91f78945b2c8718ef41fc"},"w1d1.md":{"mtime":1595517559720.3027,"size":2178,"hash":"c131c6a2d71f91557d446bac91eecf0f284ea5bf60e1f0390d9c9b3a4f78ac16"},"Information Theory.md":{"mtime":1594770228242.2905,"size":2865,"hash":"7ea75402d4f037eee8dcd436a2e7c560aca6dd8f7d1c84819322d545adcdf8d6"},"Attachments/model_values.png":{"mtime":1594681971612.2944,"size":910776,"hash":"310d1b6dce69d124f5134ed9839e4a1b38308478e4ba523fef97f9c63ebd25c4"},"[]Entropy and the Brain.md":{"mtime":1594850053077.7761,"size":909,"hash":"5f06a9b03bc97a4095ae7b2d4b4754a8c2a80d6ecee08076f71422bf148e5027"},"Ideas.md":{"mtime":1594738084540.8062,"size":197,"hash":"886525357d18dbf88520fa4f4f2f9a7a91f84807b0018f815ad1baade9a024ac"},"Marr's 3 levels of analysis.md":{"mtime":1594739127498.3342,"size":22,"hash":"4df064329264cc4a58e7f5225a9c45ae903176602bf83798a8ae4ff5b20d1019"},"Attachments/marrs_levels.png":{"mtime":1594739123100.3625,"size":597453,"hash":"c8278d409851069b958e2bff2cb8b370a020ac1cb47b485de7adb4418fd01618"},"w1d2.md":{"mtime":1594849807519.3042,"size":2177,"hash":"c069f58821ac49589e3f9a8afc60f6146ddd8b1a9916705f77916c06665cbb73"},"NMA Project.md":{"mtime":1595351459220.7944,"size":4555,"hash":"53d55a94bc2f9b902c2c26d1759c8e5ca7a3a6985435898b07bd6ac24c1c9c01"},"Quotes.md":{"mtime":1594772120968.7297,"size":130,"hash":"c83f0f2df3defdf100bb5b0de450a4446b2eb6a4ca7bb233a668298169a7f4e5"},"Science of Science.md":{"mtime":1594772914136.9836,"size":525,"hash":"e7bb25d744a2c0791e7144a21a3e3a3a61e14e6477671575e0b908fe068dd37f"},"Ioannidis_JPA_2005.md":{"mtime":1594772621496.6646,"size":300,"hash":"dc71a0ad547e92540df7e45e517707ebcc219631dab2243f1bc3d171e2225e97"},"Steinmetz_AN_2019.md":{"mtime":1595031970133.7507,"size":921,"hash":"6a2503db99f4201388071f5c79a59aaf3963b3e5143332d3c751f3445ab908d8"},"Stringer_C_2019.md":{"mtime":1595031970193.3955,"size":1517,"hash":"f1918a256d64efe84a26c743907ac262837a84678d99f44911af78c71039d401"},"Stringer_C_2019_pp.md":{"mtime":1594946509040.9783,"size":1009,"hash":"9a4880ca3627ef464d52285735d2220cdc6d42fd2300e3e7f1c0ce1dc315cc19"},"w1d3.md":{"mtime":1594915455212.3384,"size":1812,"hash":"4e2e13ffb94e90754eafeac4a558b45c5699cf420838f381d032f3cef0d52856"},"linear regression.md":{"mtime":1594922395026.355,"size":141,"hash":"c87609f312b80959ab494b2e2b0e691537894298725979e77d49eecc6f0f3dcb"},"bootstrapping.md":{"mtime":1594860573084.043,"size":390,"hash":"e8c08f779947157f272e9af62b15076ee878f9722d2ee4ce10525de22110737d"},"polynomial regression.md":{"mtime":1594849807550.2483,"size":172,"hash":"04a76bf5fa79dec448bd58db9241e961ff206d341b0eb5251dde9bae804243ca"},"bias and variance.md":{"mtime":1594859015578.8357,"size":703,"hash":"281734e97c4fda951a4fc034a17b9c4d5b2ab49a5131f4fbe575c7b09c99e8d0"},"modeling.md":{"mtime":1595527007177.5771,"size":1333,"hash":"3fa208eda146ccab3f15f4c32a4420d6a23c4d8a703b9ba01a1b46212d479d6c"},"Attachments/bias_variance.png":{"mtime":1594849904633.8325,"size":356553,"hash":"5cc6ed8fbc75aa484b786e4def21bac674be691e9c3ba517f7ba917ed65b8581"},"entropy.md":{"mtime":1595032566059.7766,"size":228,"hash":"f9600be6c80b6a912a67f5666c4f921c8df2226c526b4cfbfa39450ba04bec8d"},"cross validation.md":{"mtime":1594857247854.1763,"size":908,"hash":"a103cfc469b6d0440fe502b2d206489ac063a3c8fa2f56c034672781d7bff8d2"},"Akaike's Information Criterion.md":{"mtime":1594851833642.077,"size":524,"hash":"5e2fcab709421709bee2b5273d9ea17242bd8cfd0846f4ce029d5744ae197468"},"model fitting.md":{"mtime":1594851826198.473,"size":0,"hash":"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"},"Attachments/modeling_process.png":{"mtime":1594739191458.5508,"size":572061,"hash":"98442373e02bb6a05fab32b2979416fa94c4c830d451e76277ce2e3a76efc2bd"},"Attachments/crossvalidation_vs_bootstrapping.png":{"mtime":1594856241822.494,"size":416493,"hash":"0415cc1d9767070a0fe13c4779157bc676f9cc4d7e1e3016546d188989ea4722"},"matrix vector mulitplication.md":{"mtime":1594857653800.6084,"size":251,"hash":"c3f0f5dd0f37e596efeeeccf82fac771164fd77141f0ac4e64a5debc71fb7344"},"w1d4.md":{"mtime":1595445725325.7412,"size":1102,"hash":"fc820c8905676b665b7c516ee2f2133364f112716dab60ffed7ea6c544ce3d89"},"poisson glm.md":{"mtime":1594901070796.1816,"size":53,"hash":"8fe2e1ddb6f65209f2db407b1f689a35a73e1334ef51694a448ba84aba0d93bf"},"poisson distribution.md":{"mtime":1595359530785.0208,"size":677,"hash":"76767e86e06aac54b2845fd13e4a51051e6c2ca104db38fee3e6712344668992"},"maximum likelihood estimate.md":{"mtime":1594915435206.5225,"size":307,"hash":"e399cfcce9719911378b522d943f0e4853a6c5256bba22a159cf335e831efbbe"},"regularization.md":{"mtime":1594936285814.1472,"size":416,"hash":"5f6efe7e1cc01dd2bb9760f2dc197cc2baaaa5acc347a5afb46eb37602bc77fd"},"general linear model.md":{"mtime":1595517559738.3413,"size":435,"hash":"0a1d6deb390dd20e10f8dd50cc63f0c2b5bcac33580e8b884b0b1aad40c5f509"},"Attachments/glms .png":{"mtime":1594920945755.7395,"size":517898,"hash":"64382ccaee28330b9ad1eb2f9d0023578324be9261e3e148ba1096b8f9a28aeb"},"Attachments/Screenshot 2020-07-16 at 13.33.41.png":{"mtime":1594920974710.7502,"size":278612,"hash":"2e46f182256db59d7b39dea263e349361f5e42cf3ca20122d3594b58ced3c490"},"linear algebra.md":{"mtime":1595646611770.6633,"size":1207,"hash":"48788a59227a87a1187aee01b342659ee0a61393b8f1f8d94eb5d6129bba7918"},"Attachments/multiple_linear_regression.png":{"mtime":1594922385287.35,"size":521431,"hash":"ec175f5239320f4c785eab081de1588163a9f4cab3627cb549b09669721f5302"},"logistic regression.md":{"mtime":1594939056094.1946,"size":1674,"hash":"fb9e5928f98808162379518051a2973ba666f8364d2d2545ac4b764a234baf22"},"overfitting.md":{"mtime":1594936109638.6943,"size":92,"hash":"0e2c1d9488378c892c563e87bc56e3a92c07629f787c65441a9271be92ae8308"},"machine learning.md":{"mtime":1595445628733.9607,"size":155,"hash":"181414448b05efa2b21ab55eb0b5b70ea5468cc95ccae69b4d03fe0ea58a3ce1"},"hyperparameters.md":{"mtime":1594938832079.7603,"size":128,"hash":"df90b2665d03909ab091c23cc2dbb3f62e618a918994e10ab8e3f94f639927e8"},"basis vectors.md":{"mtime":1595367481600.587,"size":498,"hash":"9a5ab37858b47053b7c06c182d2a8d56cb9e8a45e58c2a410713409cfb3ed9db"},"Calhoun_AJ_2019.md":{"mtime":1595527251251.6565,"size":875,"hash":"b68d54767640711b4c47d4e64229a8b838b3a76efd2969671c9d129b6506bc67"},"w1d5.md":{"mtime":1595110692562.023,"size":1705,"hash":"cab39f71ad56f52f76d7b9c7b4768e9cd3845d6d04fe0d36ecc9aa73f2d363f8"},"dimensionality reduction.md":{"mtime":1595033105685.876,"size":442,"hash":"3c3bdd82c613bbc4e9c2dbae6a8786c2d5e5519d39912d28365e772d3779904c"},"questions.md":{"mtime":1595007558913.4456,"size":359,"hash":"ed3d3d81ed29b0de1531d520fd530e13779be53b4411c25170ae2e96b3dcfb87"},"Attachments/dim_red_resources.png":{"mtime":1595007619892.5527,"size":253828,"hash":"11166f3c78e33e8b1f7c6239356318bff71f4b428cce9455698e06d968eead57"},"principal component analysis.md":{"mtime":1595023781097.429,"size":1207,"hash":"1f3ab07c81de1656ce14eed5b78b432fd6b0b1d3e872b375a8b4b9030180be5e"},"factor analysis.md":{"mtime":1595008259461.4683,"size":271,"hash":"d17c395ca37fc94269b8c32355d7bb97470980e6f2e2fc9f5738600e3a97c0b7"},"gaussian-process factor analysis.md":{"mtime":1595008300749.1184,"size":174,"hash":"3d06da52bb48dcaafe044c07f8dcde2323d6dcb4f8dddcabe04e2fcf90b8aeb1"},"eigenvectors.md":{"mtime":1595012304992.2842,"size":231,"hash":"a3908abe330ec7916a7d8b58e88b548828aefc05bf0cdeac8d2bec6743defea2"},"intrinsic manifold.md":{"mtime":1595031970275.864,"size":135,"hash":"50cc3a07376e1ab9fd41c9bb7b35f65ee5447b1837485deb0fcf53c06f719886"},"neuroscience.md":{"mtime":1595031977719.9705,"size":21,"hash":"08b609180d1a23851ca891cbe5526aa79aa796ed85771097ffe962a482afb306"},"scikit-learn.md":{"mtime":1595033265537.79,"size":286,"hash":"0c33aff59fe1fdd584aa02b00e4278f62030ed0a7da0fc85c41be44d3c9ac648"},"w2d1.md":{"mtime":1595527299953.267,"size":1417,"hash":"23c558c3ab6d4991bfe246c88069e546d5cbce4b3ca5e77e860caa48a5a9b17d"},"normative models.md":{"mtime":1595265173834.9539,"size":58,"hash":"e5a990ad47a847f672f1ca69b2b77e9d1aaf8aa2e0df70abec6f5e329d2d1841"},"probability.md":{"mtime":1595284845906.5942,"size":628,"hash":"2096c413b8b6d3ce4e7347ce553ea92b4899573b1dc382dbf87d4a1940429478"},"Attachments/Distributions.png":{"mtime":1595266012162.5703,"size":907923,"hash":"d544e9fef0ada52bd3ba7293da713c5b74328e5b2e4b8f584eb72e6d7debe418"},"bayesian statistics.md":{"mtime":1595284913637.4233,"size":426,"hash":"22cbf662d8a39647d2db85cf0b2f6f4d4e6da75d205f824530f1b61816a7ad2e"},"Attachments/bayes_rule.png":{"mtime":1595266237980.806,"size":273332,"hash":"4b7159856079be6ac2aef5aa3a5fe21a374a3d4fadd07c9fc9ce6addd7bbe571"},"NMA Project Code.md":{"mtime":1595295988888.1965,"size":2930,"hash":"5943983e2f2fd7c89082bdcfd2b89a9121aad13d0b31bc78bf9a48e9b8006dcf"},"w2d2.md":{"mtime":1595387238347.466,"size":830,"hash":"90420837ea741b56a5af9a4ea3aff439a8be6b3d5bda43c0ffbeefbdb4cdac50"},"singular value decomposition.md":{"mtime":1595351454449.5342,"size":295,"hash":"d99cecc80257e3b4b1a7a96290b74eac69553a29941501a02c95c06f135df1e6"},"dynamical systems.md":{"mtime":1595353201833.9917,"size":582,"hash":"c990790b6849f94aee8ae50b8fdde77518b4cb9a5e11fc266caa1967ae6d82d6"},"eigenvalues.md":{"mtime":1595351730001.2766,"size":16,"hash":"b20e052a97acd9f74d7016d094eba807a973df079fc09238c04f4832673060f7"},"random walk.md":{"mtime":1595365588027.6697,"size":43,"hash":"3f4acb007391a4d272c9864afb367b14dc5c3661e220972a927a909782b1a610"},"Brownian motion.md":{"mtime":1595365601633.9353,"size":39,"hash":"0782d166060c686df1a7b3738da0a3fda5935cafd8656c382f6e7621db407d6d"},"Attachments/scaling_by_basis_vectors.png":{"mtime":1595367424660.2117,"size":165235,"hash":"f301373c58fabe542f41661e4ef9f08541949ebdb31f0b0cab948fc2febe46e1"},"drift diffusion.md":{"mtime":1595369256788.0024,"size":190,"hash":"79eed58abc3fd882d78833e6694a3efe07322b05649f86623dde4fe8b70c4c2e"},"Ornstein-Uhlenbeck process.md":{"mtime":1595369297892.373,"size":180,"hash":"060863b77be24b886b56504e975ff9919e1217081d3ce4866892ce3bc228b270"},"w2d3.md":{"mtime":1595527251314.0205,"size":1070,"hash":"48eee0323346fe661fead40c3586b6be508cb9284dbfa8b0d5fe53d65fe311f0"},"probabilistic graphical models.md":{"mtime":1595439429704.7556,"size":20,"hash":"04ea3179db29fcc6eadf66a2586692b8b78e413d684d7aee02c9fcdf105b3aed"},"graphical models.md":{"mtime":1595439449804.096,"size":0,"hash":"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"},"multivariate gaussian distribution.md":{"mtime":1595439503727.9634,"size":25,"hash":"9c15e9d2ee73167bb1f7878a2c1ca03447a47c97414c943f3838c10a237fb3d7"},"hidden states.md":{"mtime":1595527299993.7153,"size":264,"hash":"94f86ae844ccec7e9f88d12c753bec9c08091bc5d7e4c12032aff7f0167d2cf2"},"Attachments/hidden_state_models.png":{"mtime":1595439828468.7244,"size":359149,"hash":"66f7f6eb87c32e8ccc66211c2441ddf860556295fc3a9e31ec0bbd107c6dd4dc"},"Attachments/HMM_variants.png":{"mtime":1595440281243.4316,"size":704883,"hash":"5fd426b6b9062d77accecfd7676d4d96c6e305accaa5ed19b58c245c49fccec7"},"Kalman filter.md":{"mtime":1595527300017.8704,"size":592,"hash":"4591473e226672ba311f6645bc655b45120fb71acce78f22a1b41d79040905e5"},"causality.md":{"mtime":1595445528392.6743,"size":139,"hash":"82f97a23370aa4a37eac049dafb2d89447688955c447a5e4e2cdbb4704648bc7"},"latent state.md":{"mtime":1595527251412.548,"size":64,"hash":"9b1e21314885b648babc75a7796174cef3559a6c28e960123055ea5b2d583eac"},"latex.md":{"mtime":1595466838521.2883,"size":111,"hash":"22ca4ba99821dd779474b811cac2e45ea3c3b5d200f38f77c2c62a231948ce94"},"Attachments/composition_matrix.png":{"mtime":1595467349463.0562,"size":270037,"hash":"afe56c89acbae851e6ce8c515d0dd8db461bec5984d4c0c744916237e75d90f1"},"Attachments/determinant.png":{"mtime":1595474420142.621,"size":682925,"hash":"30f5ecd4250f6d99690be12a590a96e5e169a89c52660bbb15bda5174e775d58"},"determinant.md":{"mtime":1595562956598.3308,"size":1000,"hash":"fe233b145d248f5317215a7e3d17494a706ccc39bc0520fd03c2018b666d2460"},"Attachments/determinant 1.png":{"mtime":1595475046870.695,"size":94011,"hash":"28cae562d268f1b11514fdb03c4e884d57bf266b68a18beb4800f6ab93fd967e"},"w2d4.md":{"mtime":1595544354518.7612,"size":1185,"hash":"543ec5d23c68fa8bb8cea0790fecbf656bda6da50178efd6c88c5067cb34b84a"},"optimization.md":{"mtime":1595517570665.6821,"size":41,"hash":"c7819d70854b134aa01d5bba392f5c29b4db011a0ea3f5a6d041cbd5fbb45432"},"optimal control.md":{"mtime":1595517907089.4106,"size":217,"hash":"df663e27f496f8af839a7ce688a3dc061e503c601b3957a94b902e5877ad59c0"},"closed loop control.md":{"mtime":1595527567474.605,"size":191,"hash":"c1942996b3a698bea47e2557bfa8d043e4b2bad94503e52f612aa62df7c607e2"},"open loop control.md":{"mtime":1595527540205.1375,"size":201,"hash":"75ecc92451ab05fedf31f8624c4719c907252152f464b4642f36f1a61b28ea61"},"Attachments/closed_loop_control_formula.png":{"mtime":1595518018623.9192,"size":574388,"hash":"eb34c12ddb5154f04a241e5b6899970f65cb81eebc3441d0885479781b2e87a0"},"Attachments/control_problem_example.png":{"mtime":1595517601040.5317,"size":834835,"hash":"3b09085d25ce100e00c7f1311e745900997d2425bb42a2e730ab7f2b907a180d"},"Attachments/optimal_control_cost.png":{"mtime":1595517718090.7634,"size":237186,"hash":"b8e79310203cbe1f757b357fe8e2e5aa290545cad7c240e16abec05c041f435f"},"Attachments/open_loop_control_formula.png":{"mtime":1595517971504.9028,"size":362046,"hash":"aa521c4244191dec3282d636cc7a07e74953170406700f644167804606b2b7ce"},"Bellman equation.md":{"mtime":1595526852514.8992,"size":118,"hash":"9f73e4d7ef3ab6494db7af076ba4fcf402063ae01fba4e9a4be2edd2ccdedd7c"},"Attachments/bellman_equation.png":{"mtime":1595526838753.7766,"size":264316,"hash":"fa0ba43697d215ef316f5fc57a7377c9bf69b3e635d139a37091962e6f9b9daf"},"utility.md":{"mtime":1595526975754.05,"size":41,"hash":"c7819d70854b134aa01d5bba392f5c29b4db011a0ea3f5a6d041cbd5fbb45432"},"policy.md":{"mtime":1595527013666.0237,"size":89,"hash":"79161d7450159c534452db43dacf3d4f13d0b1730d7a8eda45c5b114165796e6"},"reinforcement learning.md":{"mtime":1595031970062.878,"size":227,"hash":"7f1a4241368c4b7d9befd0bb554073ebf168b09e8f6c59d6e1c1ad92a22685f0"},"hidden markov model.md":{"mtime":1595527376859.0176,"size":483,"hash":"866fcb3a3554aefa80ffc573f53166cc9d02b9ca3613715584aa8282699bfdfa"},"markov decision process.md":{"mtime":1595527522369.7603,"size":399,"hash":"ffc59213c6bd66036db5887090f78235a7f029e9c68d8d36732f4fb0808aac93"},"markov model.md":{"mtime":1595527369030.8582,"size":74,"hash":"519086699975061d92a9575f129acea5be3a8dd00642b168a99a2d46823619b4"},"partially observable markov decision process.md":{"mtime":1595527511597.3164,"size":90,"hash":"8fc47e0332bb99c85be301d02951b5ce03e92df38a9e525f3fe7a6e9f6a20dd7"},"linear system of equations.md":{"mtime":1595562953967.3477,"size":85,"hash":"8329649b96a699f3170101c4ff58ceb6beabac0e85324818d4d4f015e8aec834"},"Attachments/system_of_equations.png":{"mtime":1595562095220.6357,"size":284908,"hash":"e9acad23d621e8a5c9b217a93edce151e2941e2d2cfe27fee59f19027b92bffa"},"rank.md":{"mtime":1595562964184.1978,"size":243,"hash":"ce7a339123509201024da7c32cdd9124903f15369b7466cfb1a26c4647cf70ba"},"w2d5.md":{"mtime":1595633874200.1885,"size":1245,"hash":"49bb47863a9707940370e780132bd389f4809402777329214c87ff9d0349bb7c"},"agent_environment_interface.png":{"mtime":1595611616383.056,"size":497860,"hash":"768d06558f989ec68226a338c9c6c5999554ddb4635139f27a0375907d6c9803"},"Attachments/dopamine_classical_conditioning.png":{"mtime":1595614307115.1404,"size":308586,"hash":"c1000aa9c00d2ed006ee3d59b71b676892014d4b3a93980d8b0b37dfb14ab0bc"}},"metadata":{"fd8a676776cc1885281cd316c5a451e3191d9581fca05816e07b96b2ecabfe86":{"links":[],"embeds":[],"tags":[],"headings":[]},"6b0963b03e35ed281e2898fa8b6beae36f8685c63a257965f936ddd5c5cbbf75":{"links":[{"line":0,"link":"Obsidian","original":"[[Obsidian]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[],"headings":[]},"2be28d55974ca863bce6a7c1803cb352a48c7cf3cb36d0c1520be2692db2b8dd":{"links":[{"line":0,"link":"Hause Tips for Obsidian","original":"[[Hause Tips for Obsidian]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[],"headings":[]},"37558d452555f1e9ea676ca7dbc4db1aaf8f0fab1b848f0bb4de8ec12200f184":{"links":[{"line":0,"link":"PKM","original":"[[PKM| Personal Knowledge Management]]","displayText":"Personal Knowledge Management","beforeContext":"","afterContext":""}],"embeds":[],"tags":[],"headings":[]},"eb80fca0a8e871bb20dde6576bec37a7b35361ae60478e6a55c67346e9d6932b":{"links":[{"line":8,"link":"dual system","original":"[[dual system]]","displayText":"","beforeContext":"","afterContext":""},{"line":9,"link":"time pressure","original":"[[time pressure]]","displayText":"","beforeContext":"","afterContext":""},{"line":10,"link":"framing effect","original":"[[framing effect]]","displayText":"","beforeContext":"","afterContext":""},{"line":11,"link":"risky choice","original":"[[risky choice]]","displayText":"","beforeContext":"","afterContext":""},{"line":12,"link":"Ian D. Roberts","original":"[[Ian D. Roberts]]","displayText":"","beforeContext":"","afterContext":""},{"line":22,"link":"ddm","original":"[[ddm]]","displayText":"","beforeContext":"idea: ","afterContext":", for example, dominated early by system 1, which in turn is sensitive to the framing effect"}],"embeds":[],"tags":[{"line":4,"tag":"#draft"},{"line":4,"tag":"#labmeeting"},{"line":4,"tag":"#paper"}],"headings":[{"line":0,"heading":"Info","level":1},{"line":15,"heading":"Notes","level":1},{"line":16,"heading":"Summary","level":2},{"line":29,"heading":"Thoughts","level":2},{"line":48,"heading":"Resources","level":1}]},"3bea295b17a13205b66cc0f48987d96a41f2fbb588dc83f0d1c09f46cf234236":{"links":[],"embeds":[],"tags":[{"line":1,"tag":"#rate1"},{"line":2,"tag":"#followup"}],"headings":[{"line":0,"heading":"Tags","level":2}]},"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855":{"links":[],"embeds":[],"tags":[],"headings":[]},"750e462b2c108607ea0fe4592eec77ec8f02d73338f9a99b702caf3311250af6":{"links":[],"embeds":[],"tags":[],"headings":[]},"b4c7407e6cf03ca6211552bed047ea54b447d8c993d91f78945b2c8718ef41fc":{"links":[],"embeds":[],"tags":[{"line":0,"tag":"#neuromatch"}],"headings":[]},"310d1b6dce69d124f5134ed9839e4a1b38308478e4ba523fef97f9c63ebd25c4":{"links":[],"embeds":[],"tags":[],"headings":[]},"886525357d18dbf88520fa4f4f2f9a7a91f84807b0018f815ad1baade9a024ac":{"links":[{"line":0,"link":"Exponential distribution","original":"[[Exponential distribution|exponential]]","displayText":"exponential","beforeContext":"Check the shape of the distribution of letters in the English language. And perhaps also bi-grams. Is it ","afterContext":" like the ISI of neurons?"},{"line":0,"link":"Inter spike interval","original":"[[Inter spike interval|ISI]]","displayText":"ISI","beforeContext":"Check the shape of the distribution of letters in the English language. And perhaps also bi-grams. Is it exponential like the ","afterContext":" of neurons?"}],"embeds":[],"tags":[],"headings":[]},"c8278d409851069b958e2bff2cb8b370a020ac1cb47b485de7adb4418fd01618":{"links":[],"embeds":[],"tags":[],"headings":[]},"4df064329264cc4a58e7f5225a9c45ae903176602bf83798a8ae4ff5b20d1019":{"links":[],"embeds":[{"line":1,"link":"marrs_levels.png","original":"![[marrs_levels.png]]","beforeContext":"","afterContext":""}],"tags":[],"headings":[]},"98442373e02bb6a05fab32b2979416fa94c4c830d451e76277ce2e3a76efc2bd":{"links":[],"embeds":[],"tags":[],"headings":[]},"7ea75402d4f037eee8dcd436a2e7c560aca6dd8f7d1c84819322d545adcdf8d6":{"links":[{"line":0,"link":"Information Theory","original":"[[Information Theory]]","displayText":"","beforeContext":"","afterContext":"Claude Shannon"},{"line":0,"link":"Claude Shannon","original":"[[Claude Shannon]]","displayText":"","beforeContext":"Information Theory","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":5,"heading":"Resources","level":1}]},"c83f0f2df3defdf100bb5b0de450a4446b2eb6a4ca7bb233a668298169a7f4e5":{"links":[{"line":1,"link":"Science of Science","original":"[[Science of Science]]","displayText":"","beforeContext":"Prof. Brian Nosek","afterContext":""}],"embeds":[],"tags":[],"headings":[]},"dc71a0ad547e92540df7e45e517707ebcc219631dab2243f1bc3d171e2225e97":{"links":[{"line":9,"link":"Science of Science","original":"[[Science of Science]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[{"line":4,"tag":"#paper"}],"headings":[{"line":0,"heading":"Info","level":1},{"line":12,"heading":"Notes","level":1},{"line":13,"heading":"Summary","level":2},{"line":16,"heading":"Thoughts","level":2},{"line":19,"heading":"Resources","level":1}]},"e7bb25d744a2c0791e7144a21a3e3a3a61e14e6477671575e0b908fe068dd37f":{"links":[{"line":8,"link":"Ioannidis_JPA_2005","original":"[[Ioannidis_JPA_2005]]","displayText":"","beforeContext":"Why Most Published Research Findings Are FalseWhy Most Published Research Findings Are False ","afterContext":" #paper"}],"embeds":[],"tags":[{"line":4,"tag":"#video"},{"line":8,"tag":"#paper"},{"line":10,"tag":"#article"},{"line":12,"tag":"#article"}],"headings":[{"line":3,"heading":"Resources","level":1}]},"5d8917a9c44a9cc7ed59b39a2accdf97a3001ab6ac6f366a6cd3c39dd2a7f829":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":2,"heading":"Notes","level":1},{"line":4,"heading":"Resources","level":1}]},"24c3232c7639311654dfb01e32ec2cad06b2f3e438b07b95b9b8ff3a92a00e31":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"Marr’s Three Levels"},{"line":0,"link":"Marr's Three Levels","original":"[[Marr's Three Levels]]","displayText":"Marr’s Three Levels","beforeContext":"modeling","afterContext":""}],"embeds":[{"line":13,"link":"Pasted image 1.png","original":"![[Pasted image 1.png]]","beforeContext":"","afterContext":""}],"tags":[],"headings":[{"line":4,"heading":"Notes","level":1},{"line":12,"heading":"Resources","level":1}]},"c069f58821ac49589e3f9a8afc60f6146ddd8b1a9916705f77916c06665cbb73":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"Motion Perception"},{"line":0,"link":"Motion Perception","original":"[[Motion Perception]]","displayText":"","beforeContext":"modeling","afterContext":""}],"embeds":[],"tags":[{"line":3,"tag":"#neuromatch"}],"headings":[{"line":5,"heading":"Modeling Practice","level":1},{"line":8,"heading":"10 steps of modeling (Blohm et al., 2019) in two notebooks:","level":3},{"line":28,"heading":"Take Aways","level":1},{"line":43,"heading":"Resources","level":1}]},"04a76bf5fa79dec448bd58db9241e961ff206d341b0eb5251dde9bae804243ca":{"links":[{"line":1,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":""},{"line":6,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"Collab NotebookCollab Notebook from ","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":5,"heading":"Resources","level":1}]},"5cc6ed8fbc75aa484b786e4def21bac674be691e9c3ba517f7ba917ed65b8581":{"links":[],"embeds":[],"tags":[],"headings":[]},"5f06a9b03bc97a4095ae7b2d4b4754a8c2a80d6ecee08076f71422bf148e5027":{"links":[{"line":4,"link":"Exponential distribution","original":"[[Exponential distribution|exponential distribution]]","displayText":"exponential distribution","beforeContext":"Entropy used as a measure to show that the ","afterContext":" can contain more information (with the same number of neuron spikes) than a uniform distribution, which is generally seen as the limit of a distribution’s information."},{"line":4,"link":"Uniform distribution","original":"[[Uniform distribution|uniform distribution]]","displayText":"uniform distribution","beforeContext":"Entropy used as a measure to show that the exponential distribution can contain more information (with the same number of neuron spikes) than a ","afterContext":", which is generally seen as the limit of a distribution’s information."},{"line":8,"link":"Ideas","original":"[[Ideas|Idea]]","displayText":"Idea","beforeContext":"","afterContext":": Check the shape of the distribution of letters in the English language. And perhaps also bi-grams."},{"line":11,"link":"entropy","original":"[[entropy|entropy]]","displayText":"","beforeContext":"Neuromatch notebook dealing with ","afterContext":" and the brain"}],"embeds":[],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":10,"heading":"Resources","level":1}]},"5e2fcab709421709bee2b5273d9ea17242bd8cfd0846f4ce029d5744ae197468":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"model fitting"},{"line":0,"link":"model fitting","original":"[[model fitting]]","displayText":"","beforeContext":"modeling","afterContext":""},{"line":13,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"Appendix of this Collab notebookthis Collab notebook from ","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":12,"heading":"Resources","level":1}]},"0415cc1d9767070a0fe13c4779157bc676f9cc4d7e1e3016546d188989ea4722":{"links":[],"embeds":[],"tags":[],"headings":[]},"a103cfc469b6d0440fe502b2d206489ac063a3c8fa2f56c034672781d7bff8d2":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":""},{"line":11,"link":"general linear model","original":"[[general linear model|GLM]]","displayText":"GLM","beforeContext":"","afterContext":" is convex"},{"line":18,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"Collab notebookCollab notebook from ","afterContext":""}],"embeds":[{"line":13,"link":"crossvalidation_vs_bootstrapping.png","original":"![[crossvalidation_vs_bootstrapping.png]]","beforeContext":"Comparision of crossvalidation and bootstrapping","afterContext":""}],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":17,"heading":"Resources","level":1}]},"c3f0f5dd0f37e596efeeeccf82fac771164fd77141f0ac4e64a5debc71fb7344":{"links":[{"line":0,"link":"matrices","original":"[[matrices]]","displayText":"","beforeContext":"","afterContext":"linear algebranumpypythonprogramming"},{"line":0,"link":"linear algebra","original":"[[linear algebra]]","displayText":"","beforeContext":"matrices","afterContext":"numpypythonprogramming"},{"line":0,"link":"numpy","original":"[[numpy]]","displayText":"","beforeContext":"matriceslinear algebra","afterContext":"pythonprogramming"},{"line":0,"link":"python","original":"[[python]]","displayText":"","beforeContext":"matriceslinear algebranumpy","afterContext":"programming"},{"line":0,"link":"programming","original":"[[programming]]","displayText":"","beforeContext":"matriceslinear algebranumpypython","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":6,"heading":"Notes","level":1},{"line":9,"heading":"Resources","level":1}]},"281734e97c4fda951a4fc034a17b9c4d5b2ab49a5131f4fbe575c7b09c99e8d0":{"links":[{"line":0,"link":"statistics","original":"[[statistics]]","displayText":"","beforeContext":"","afterContext":"modeling"},{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"statistics","afterContext":""},{"line":11,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"Collab notebookCollab notebook from ","afterContext":""}],"embeds":[{"line":5,"link":"bias_variance.png","original":"![[bias_variance.png]]","beforeContext":"","afterContext":""}],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":8,"heading":"Resources","level":1}]},"e8c08f779947157f272e9af62b15076ee878f9722d2ee4ce10525de22110737d":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"model fittingstatistics"},{"line":0,"link":"model fitting","original":"[[model fitting]]","displayText":"","beforeContext":"modeling","afterContext":"statistics"},{"line":0,"link":"statistics","original":"[[statistics]]","displayText":"","beforeContext":"modelingmodel fitting","afterContext":""},{"line":12,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"Collab notebookCollab notebook from ","afterContext":"."}],"embeds":[],"tags":[],"headings":[{"line":4,"heading":"Notes","level":1},{"line":11,"heading":"Resources","level":1}]},"8fe2e1ddb6f65209f2db407b1f689a35a73e1334ef51694a448ba84aba0d93bf":{"links":[{"line":0,"link":"poisson distribution","original":"[[poisson distribution]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":2,"heading":"Notes","level":1},{"line":4,"heading":"Resources","level":1}]},"e399cfcce9719911378b522d943f0e4853a6c5256bba22a159cf335e831efbbe":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"model fitting"},{"line":0,"link":"model fitting","original":"[[model fitting]]","displayText":"","beforeContext":"modeling","afterContext":""},{"line":4,"link":"mean squared error","original":"[[mean squared error|MSE]]","displayText":"MSE","beforeContext":"More flexible than ","afterContext":""},{"line":9,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"Dylan Festa’s notesnotes (","afterContext":" TA)"}],"embeds":[],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":8,"heading":"Resources","level":1}]},"4e2e13ffb94e90754eafeac4a558b45c5699cf420838f381d032f3cef0d52856":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"model fittinglinear regressionbootstrappingmultiple linear regressionmean squared errormaximum likelihood estimateobjective functionpolynomial regressionbias and variancecross validationAkaike’s Information Criterion"},{"line":0,"link":"model fitting","original":"[[model fitting]]","displayText":"","beforeContext":"modeling","afterContext":"linear regressionbootstrappingmultiple linear regressionmean squared errormaximum likelihood estimateobjective functionpolynomial regressionbias and variancecross validationAkaike’s Information Criterion"},{"line":0,"link":"linear regression","original":"[[linear regression]]","displayText":"","beforeContext":"modelingmodel fitting","afterContext":"bootstrappingmultiple linear regressionmean squared errormaximum likelihood estimateobjective functionpolynomial regressionbias and variancecross validationAkaike’s Information Criterion"},{"line":0,"link":"bootstrapping","original":"[[bootstrapping]]","displayText":"","beforeContext":"modelingmodel fittinglinear regression","afterContext":"multiple linear regressionmean squared errormaximum likelihood estimateobjective functionpolynomial regressionbias and variancecross validationAkaike’s Information Criterion"},{"line":0,"link":"multiple linear regression","original":"[[multiple linear regression]]","displayText":"","beforeContext":"modelingmodel fittinglinear regressionbootstrapping","afterContext":"mean squared errormaximum likelihood estimateobjective functionpolynomial regressionbias and variancecross validationAkaike’s Information Criterion"},{"line":0,"link":"mean squared error","original":"[[mean squared error]]","displayText":"","beforeContext":"modelingmodel fittinglinear regressionbootstrappingmultiple linear regression","afterContext":"maximum likelihood estimateobjective functionpolynomial regressionbias and variancecross validationAkaike’s Information Criterion"},{"line":0,"link":"maximum likelihood estimate","original":"[[maximum likelihood estimate]]","displayText":"","beforeContext":"modelingmodel fittinglinear regressionbootstrappingmultiple linear regressionmean squared error","afterContext":"objective functionpolynomial regressionbias and variancecross validationAkaike’s Information Criterion"},{"line":0,"link":"objective function","original":"[[objective function]]","displayText":"","beforeContext":"modelingmodel fittinglinear regressionbootstrappingmultiple linear regressionmean squared errormaximum likelihood estimate","afterContext":"polynomial regressionbias and variancecross validationAkaike’s Information Criterion"},{"line":0,"link":"polynomial regression","original":"[[polynomial regression]]","displayText":"","beforeContext":"modelingmodel fittinglinear regressionbootstrappingmultiple linear regressionmean squared errormaximum likelihood estimateobjective function","afterContext":"bias and variancecross validationAkaike’s Information Criterion"},{"line":0,"link":"bias and variance","original":"[[bias and variance]]","displayText":"","beforeContext":"modelingmodel fittinglinear regressionbootstrappingmultiple linear regressionmean squared errormaximum likelihood estimateobjective functionpolynomial regression","afterContext":"cross validationAkaike’s Information Criterion"},{"line":0,"link":"cross validation","original":"[[cross validation]]","displayText":"","beforeContext":"modelingmodel fittinglinear regressionbootstrappingmultiple linear regressionmean squared errormaximum likelihood estimateobjective functionpolynomial regressionbias and variance","afterContext":"Akaike’s Information Criterion"},{"line":0,"link":"Akaike's Information Criterion","original":"[[Akaike's Information Criterion]]","displayText":"Akaike’s Information Criterion","beforeContext":"modelingmodel fittinglinear regressionbootstrappingmultiple linear regressionmean squared errormaximum likelihood estimateobjective functionpolynomial regressionbias and variancecross validation","afterContext":""},{"line":26,"link":"mean squared error","original":"[[mean squared error|MSE]]","displayText":"MSE","beforeContext":"Models as functions (","afterContext":"/OLS)"},{"line":30,"link":"maximum likelihood estimate","original":"[[maximum likelihood estimate|MLE]]","displayText":"MLE","beforeContext":"Models as generators (","afterContext":")"},{"line":42,"link":"Akaike's Information Criterion","original":"[[Akaike's Information Criterion|AIC]]","displayText":"AIC","beforeContext":"e.g. ","afterContext":""},{"line":44,"link":"cross validation","original":"[[cross validation|Cross validation]]","displayText":"Cross validation","beforeContext":"","afterContext":""},{"line":51,"link":"linear regression","original":"[[linear regression|linear model]]","displayText":"linear model","beforeContext":"A ","afterContext":" can have non-linear inputs"},{"line":52,"link":"bias and variance","original":"[[bias and variance]]","displayText":"","beforeContext":"Total model error is a combination of ","afterContext":""},{"line":53,"link":"bootstrapping","original":"[[bootstrapping]]","displayText":"","beforeContext":"Use ","afterContext":" to estimate uncertainty"}],"embeds":[],"tags":[{"line":13,"tag":"#neuromatch"}],"headings":[{"line":15,"heading":"Modeling Fitting","level":1},{"line":16,"heading":"Two guiding principles of science:","level":3},{"line":25,"heading":"Two model fitting philosophies:","level":3},{"line":39,"heading":"Two philosophies for comparing models:","level":3},{"line":48,"heading":"Take Aways","level":1},{"line":57,"heading":"Resources","level":1}]},"64382ccaee28330b9ad1eb2f9d0023578324be9261e3e148ba1096b8f9a28aeb":{"links":[],"embeds":[],"tags":[],"headings":[]},"2e46f182256db59d7b39dea263e349361f5e42cf3ca20122d3594b58ced3c490":{"links":[],"embeds":[],"tags":[],"headings":[]},"ec175f5239320f4c785eab081de1588163a9f4cab3627cb549b09669721f5302":{"links":[],"embeds":[],"tags":[],"headings":[]},"c87609f312b80959ab494b2e2b0e691537894298725979e77d49eecc6f0f3dcb":{"links":[{"line":0,"link":"linear regression","original":"[[linear regression]]","displayText":"","beforeContext":"","afterContext":"multiple linear regression"},{"line":0,"link":"multiple linear regression","original":"[[multiple linear regression]]","displayText":"","beforeContext":"linear regression","afterContext":""}],"embeds":[{"line":6,"link":"multiple_linear_regression.png","original":"![[multiple_linear_regression.png]]","beforeContext":"","afterContext":""}],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":8,"heading":"Resources","level":1}]},"0e2c1d9488378c892c563e87bc56e3a92c07629f787c65441a9271be92ae8308":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"machine learning"},{"line":0,"link":"machine learning","original":"[[machine learning]]","displayText":"","beforeContext":"modeling","afterContext":""},{"line":4,"link":"regularization","original":"[[regularization]]","displayText":"","beforeContext":"corrected using ","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":6,"heading":"Resources","level":1}]},"5f6efe7e1cc01dd2bb9760f2dc197cc2baaaa5acc347a5afb46eb37602bc77fd":{"links":[{"line":1,"link":"overfitting","original":"[[overfitting]]","displayText":"","beforeContext":"Used to avoid ","afterContext":"!"},{"line":2,"link":"general linear model","original":"[[general linear model|glm]]","displayText":"glm","beforeContext":"shrinks the parameters in ","afterContext":" toward 0"},{"line":8,"link":"gaussian distribution","original":"[[gaussian distribution]]","displayText":"","beforeContext":"Ridge Regression: linear ","afterContext":" + L2"},{"line":11,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"Intro videoIntro video w1d4 ","afterContext":""}],"embeds":[{"line":6,"link":"Screenshot 2020-07-16 at 13.33.41.png","original":"![[Screenshot 2020-07-16 at 13.33.41.png]]","beforeContext":"","afterContext":""}],"tags":[],"headings":[{"line":0,"heading":"Notes","level":1},{"line":10,"heading":"Resources","level":1}]},"df90b2665d03909ab091c23cc2dbb3f62e618a918994e10ab8e3f94f639927e8":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"model fitting"},{"line":0,"link":"model fitting","original":"[[model fitting]]","displayText":"","beforeContext":"modeling","afterContext":""},{"line":4,"link":"cross validation","original":"[[cross validation]]","displayText":"","beforeContext":"Make sure to use ","afterContext":" to select your hyperparameters."}],"embeds":[],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":7,"heading":"Resources","level":1}]},"fb9e5928f98808162379518051a2973ba666f8364d2d2545ac4b764a234baf22":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":""},{"line":3,"link":"general linear model","original":"[[general linear model|GLM]]","displayText":"GLM","beforeContext":"Also known as Bernoulli ","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":2,"heading":"Notes","level":1},{"line":6,"heading":"Details","level":2},{"line":11,"heading":"The logistic link function","level":3},{"line":17,"heading":"The Bernoulli likelihood","level":3},{"line":39,"heading":"Resources","level":1}]},"9a4880ca3627ef464d52285735d2220cdc6d42fd2300e3e7f1c0ce1dc315cc19":{"links":[],"embeds":[],"tags":[{"line":4,"tag":"#paper"}],"headings":[{"line":0,"heading":"Info","level":1},{"line":12,"heading":"Notes","level":1},{"line":13,"heading":"Summary","level":2},{"line":22,"heading":"Thoughts","level":2},{"line":25,"heading":"Resources","level":1}]},"3b6bde5694f31ac3bc688c977cdb369fd77d0c8c71f5a53685ea01aa14dd9d2c":{"links":[],"embeds":[],"tags":[{"line":5,"tag":"#paper"}],"headings":[{"line":0,"heading":"Info","level":1},{"line":13,"heading":"Notes","level":1},{"line":14,"heading":"Summary","level":2},{"line":17,"heading":"Thoughts","level":2},{"line":20,"heading":"Resources","level":1}]},"ed3d3d81ed29b0de1531d520fd530e13779be53b4411c25170ae2e96b3dcfb87":{"links":[],"embeds":[],"tags":[],"headings":[]},"11166f3c78e33e8b1f7c6239356318bff71f4b428cce9455698e06d968eead57":{"links":[],"embeds":[],"tags":[],"headings":[]},"d17c395ca37fc94269b8c32355d7bb97470980e6f2e2fc9f5738600e3a97c0b7":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"dimensionality reductionprincipal component analysisgaussian-process factor analysis"},{"line":0,"link":"dimensionality reduction","original":"[[dimensionality reduction]]","displayText":"","beforeContext":"modeling","afterContext":"principal component analysisgaussian-process factor analysis"},{"line":0,"link":"principal component analysis","original":"[[principal component analysis]]","displayText":"","beforeContext":"modelingdimensionality reduction","afterContext":"gaussian-process factor analysis"},{"line":0,"link":"gaussian-process factor analysis","original":"[[gaussian-process factor analysis]]","displayText":"","beforeContext":"modelingdimensionality reductionprincipal component analysis","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":6,"heading":"Notes","level":1},{"line":12,"heading":"Resources","level":1}]},"3d06da52bb48dcaafe044c07f8dcde2323d6dcb4f8dddcabe04e2fcf90b8aeb1":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"dimensionality reductionprincipal component analysisfactor analysis"},{"line":0,"link":"dimensionality reduction","original":"[[dimensionality reduction]]","displayText":"","beforeContext":"modeling","afterContext":"principal component analysisfactor analysis"},{"line":0,"link":"principal component analysis","original":"[[principal component analysis]]","displayText":"","beforeContext":"modelingdimensionality reduction","afterContext":"factor analysis"},{"line":0,"link":"factor analysis","original":"[[factor analysis]]","displayText":"","beforeContext":"modelingdimensionality reductionprincipal component analysis","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":5,"heading":"Notes","level":1},{"line":9,"heading":"Resources","level":1}]},"a3908abe330ec7916a7d8b58e88b548828aefc05bf0cdeac8d2bec6743defea2":{"links":[{"line":0,"link":"algebra","original":"[[algebra]]","displayText":"","beforeContext":"","afterContext":"linear algebra"},{"line":0,"link":"linear algebra","original":"[[linear algebra]]","displayText":"","beforeContext":"algebra","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":5,"heading":"Resources","level":1}]},"1f3ab07c81de1656ce14eed5b78b432fd6b0b1d3e872b375a8b4b9030180be5e":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"dimensionality reductionfactor analysiseigenvectors"},{"line":0,"link":"dimensionality reduction","original":"[[dimensionality reduction]]","displayText":"","beforeContext":"modeling","afterContext":"factor analysiseigenvectors"},{"line":0,"link":"factor analysis","original":"[[factor analysis]]","displayText":"","beforeContext":"modelingdimensionality reduction","afterContext":"eigenvectors"},{"line":0,"link":"eigenvectors","original":"[[eigenvectors]]","displayText":"","beforeContext":"modelingdimensionality reductionfactor analysis","afterContext":""},{"line":6,"link":"principal component analysis","original":"[[principal component analysis|PCA]]","displayText":"PCA","beforeContext":"","afterContext":" represents data in a new orthonormal basis defined by the eigenvectors of the covariance matrix"},{"line":6,"link":"eigenvectors","original":"[[eigenvectors]]","displayText":"","beforeContext":"PCA represents data in a new orthonormal basis defined by the ","afterContext":" of the covariance matrix"},{"line":6,"link":"covariance matrix","original":"[[covariance matrix]]","displayText":"","beforeContext":"PCA represents data in a new orthonormal basis defined by the eigenvectors of the ","afterContext":""},{"line":22,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"","afterContext":" Collab notebookCollab notebook"}],"embeds":[],"tags":[],"headings":[{"line":5,"heading":"Notes","level":1},{"line":21,"heading":"Resources","level":1}]},"08b609180d1a23851ca891cbe5526aa79aa796ed85771097ffe962a482afb306":{"links":[],"embeds":[],"tags":[],"headings":[{"line":1,"heading":"Notes","level":1},{"line":3,"heading":"Resources","level":1}]},"6ba62326215ae120408dd81a2ec779a32b0086110ae1df89f6b7e156ee92aee1":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"neuroscienceMovement"},{"line":0,"link":"neuroscience","original":"[[neuroscience]]","displayText":"","beforeContext":"modeling","afterContext":"Movement"},{"line":0,"link":"Movement","original":"[[Movement]]","displayText":"","beforeContext":"modelingneuroscience","afterContext":""}],"embeds":[],"tags":[{"line":4,"tag":"#neuromatch"}],"headings":[{"line":6,"heading":"Notes","level":1}]},"8bb4a46172ce52d59dab26358ab09886c8c1c2df4450a2086c742b2c70df5a02":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"neuroscience"},{"line":0,"link":"neuroscience","original":"[[neuroscience]]","displayText":"","beforeContext":"modeling","afterContext":""}],"embeds":[{"line":9,"link":"model_values.png","original":"![[model_values.png]]","beforeContext":"","afterContext":""}],"tags":[{"line":3,"tag":"#neuromatch"}],"headings":[{"line":5,"heading":"Notes","level":1},{"line":8,"heading":"Resources","level":1}]},"7f1a4241368c4b7d9befd0bb554073ebf168b09e8f6c59d6e1c1ad92a22685f0":{"links":[{"line":1,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"machine learningneuroscience"},{"line":1,"link":"machine learning","original":"[[machine learning]]","displayText":"","beforeContext":"modeling","afterContext":"neuroscience"},{"line":1,"link":"neuroscience","original":"[[neuroscience]]","displayText":"","beforeContext":"modelingmachine learning","afterContext":""},{"line":10,"link":"Shadlen_MN_2001","original":"[[Shadlen_MN_2001|Shadlen paper]]","displayText":"Shadlen paper","beforeContext":"Dopamine ","afterContext":""}],"embeds":[],"tags":[{"line":5,"tag":"#neuromatch"}],"headings":[{"line":7,"heading":"Notes","level":1}]},"7fd5efcd42728f471966a8dca3d3a2684c1b5b1a859caadf0a071ab4941adaa7":{"links":[{"line":0,"link":"Konrad Kording","original":"[[Konrad Kording]]","displayText":"","beforeContext":"","afterContext":"neuroscience"},{"line":0,"link":"neuroscience","original":"[[neuroscience]]","displayText":"","beforeContext":"Konrad Kording","afterContext":""},{"line":7,"link":"w1d1","original":"[[w1d1]]","displayText":"","beforeContext":"","afterContext":"w1d2"},{"line":7,"link":"w1d2","original":"[[w1d2]]","displayText":"","beforeContext":"w1d1","afterContext":""}],"embeds":[{"line":11,"link":"Pod People","original":"![[Pod People]]","beforeContext":"","afterContext":""}],"tags":[{"line":3,"tag":"#workshop"},{"line":3,"tag":"#neuromatch"}],"headings":[{"line":6,"heading":"Days","level":1},{"line":10,"heading":"Pod People","level":1},{"line":13,"heading":"Questions","level":1}]},"6a2503db99f4201388071f5c79a59aaf3963b3e5143332d3c751f3445ab908d8":{"links":[{"line":10,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"","afterContext":""},{"line":11,"link":"NMA Project","original":"[[NMA Project]]","displayText":"","beforeContext":"","afterContext":""},{"line":12,"link":"neuroscience","original":"[[neuroscience]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[{"line":5,"tag":"#paper"},{"line":5,"tag":"#neuromatch"}],"headings":[{"line":0,"heading":"Info","level":1},{"line":14,"heading":"Notes","level":1},{"line":15,"heading":"Summary","level":2},{"line":22,"heading":"Thoughts","level":2},{"line":24,"heading":"Resources","level":1}]},"f1918a256d64efe84a26c743907ac262837a84678d99f44911af78c71039d401":{"links":[{"line":10,"link":"NMA Project","original":"[[NMA Project]]","displayText":"","beforeContext":"","afterContext":""},{"line":11,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"","afterContext":""},{"line":12,"link":"neuroscience","original":"[[neuroscience]]","displayText":"","beforeContext":"","afterContext":""},{"line":13,"link":"Stringer_C_2019_pp","original":"[[Stringer_C_2019_pp]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[{"line":5,"tag":"#paper"}],"headings":[{"line":0,"heading":"Info","level":1},{"line":15,"heading":"Notes","level":1},{"line":16,"heading":"Summary","level":2},{"line":32,"heading":"Thoughts","level":2},{"line":35,"heading":"Resources","level":1}]},"50cc3a07376e1ab9fd41c9bb7b35f65ee5447b1837485deb0fcf53c06f719886":{"links":[{"line":0,"link":"neuroscience","original":"[[neuroscience]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":2,"heading":"Notes","level":1},{"line":4,"heading":"Resources","level":1}]},"f9600be6c80b6a912a67f5666c4f921c8df2226c526b4cfbfa39450ba04bec8d":{"links":[{"line":0,"link":"Information Theory","original":"[[Information Theory]]","displayText":"","beforeContext":"","afterContext":""},{"line":1,"link":"Entropy and the Brain","original":"[[Entropy and the Brain]]","displayText":"","beforeContext":"","afterContext":""},{"line":2,"link":"Mutual Information","original":"[[Mutual Information]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":4,"heading":"Notes","level":1},{"line":6,"heading":"Resources","level":1}]},"3c3bdd82c613bbc4e9c2dbae6a8786c2d5e5519d39912d28365e772d3779904c":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"Neuromatchw1d5"},{"line":0,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"modeling","afterContext":"w1d5"},{"line":0,"link":"w1d5","original":"[[w1d5]]","displayText":"","beforeContext":"modelingNeuromatch","afterContext":""},{"line":5,"link":"principal component analysis","original":"[[principal component analysis|PCA]]","displayText":"PCA","beforeContext":"Simplest method: ","afterContext":""},{"line":8,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"","afterContext":" playlistplaylist"}],"embeds":[{"line":12,"link":"dim_red_resources.png","original":"![[dim_red_resources.png]]","beforeContext":"","afterContext":""}],"tags":[],"headings":[{"line":4,"heading":"Notes","level":1},{"line":7,"heading":"Resources","level":1}]},"0c33aff59fe1fdd584aa02b00e4278f62030ed0a7da0fc85c41be44d3c9ac648":{"links":[{"line":1,"link":"machine learning","original":"[[machine learning]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":5,"heading":"Resources","level":1}]},"cab39f71ad56f52f76d7b9c7b4768e9cd3845d6d04fe0d36ecc9aa73f2d363f8":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"model fittingdimensionality reductionprincipal component analysisfactor analysislinear discriminant analysisblind source separationindependent components analysisintrinsic manifold"},{"line":0,"link":"model fitting","original":"[[model fitting]]","displayText":"","beforeContext":"modeling","afterContext":"dimensionality reductionprincipal component analysisfactor analysislinear discriminant analysisblind source separationindependent components analysisintrinsic manifold"},{"line":0,"link":"dimensionality reduction","original":"[[dimensionality reduction]]","displayText":"","beforeContext":"modelingmodel fitting","afterContext":"principal component analysisfactor analysislinear discriminant analysisblind source separationindependent components analysisintrinsic manifold"},{"line":0,"link":"principal component analysis","original":"[[principal component analysis]]","displayText":"","beforeContext":"modelingmodel fittingdimensionality reduction","afterContext":"factor analysislinear discriminant analysisblind source separationindependent components analysisintrinsic manifold"},{"line":0,"link":"factor analysis","original":"[[factor analysis]]","displayText":"","beforeContext":"modelingmodel fittingdimensionality reductionprincipal component analysis","afterContext":"linear discriminant analysisblind source separationindependent components analysisintrinsic manifold"},{"line":0,"link":"linear discriminant analysis","original":"[[linear discriminant analysis]]","displayText":"","beforeContext":"modelingmodel fittingdimensionality reductionprincipal component analysisfactor analysis","afterContext":"blind source separationindependent components analysisintrinsic manifold"},{"line":0,"link":"blind source separation","original":"[[blind source separation]]","displayText":"","beforeContext":"modelingmodel fittingdimensionality reductionprincipal component analysisfactor analysislinear discriminant analysis","afterContext":"independent components analysisintrinsic manifold"},{"line":0,"link":"independent components analysis","original":"[[independent components analysis]]","displayText":"","beforeContext":"modelingmodel fittingdimensionality reductionprincipal component analysisfactor analysislinear discriminant analysisblind source separation","afterContext":"intrinsic manifold"},{"line":0,"link":"intrinsic manifold","original":"[[intrinsic manifold]]","displayText":"","beforeContext":"modelingmodel fittingdimensionality reductionprincipal component analysisfactor analysislinear discriminant analysisblind source separationindependent components analysis","afterContext":""},{"line":16,"link":"questions","original":"[[questions]]","displayText":"","beforeContext":"The brain has fewer degrees of freedom at its disposal than the number of neurons at play ","afterContext":""},{"line":24,"link":"questions","original":"[[questions]]","displayText":"","beforeContext":"Latent dynamical systems (LDS, LFADS) ","afterContext":""},{"line":30,"link":"independent components analysis","original":"[[independent components analysis|ICA]]","displayText":"ICA","beforeContext":"","afterContext":""},{"line":31,"link":"principal component analysis","original":"[[principal component analysis|PCA]]","displayText":"PCA","beforeContext":"requires statistical independence of components, not that they are uncorrelated like ","afterContext":" (stronger condition)"},{"line":32,"link":"blind source separation","original":"[[blind source separation]]","displayText":"","beforeContext":"Can be use for ","afterContext":""},{"line":37,"link":"principal component analysis","original":"[[principal component analysis]]","displayText":"","beforeContext":"Simplest method: ","afterContext":""}],"embeds":[],"tags":[{"line":10,"tag":"#neuromatch"}],"headings":[{"line":12,"heading":"Dimensionality Reduction","level":1},{"line":36,"heading":"Take Aways","level":1},{"line":51,"heading":"Resources","level":1}]},"e5a990ad47a847f672f1ca69b2b77e9d1aaf8aa2e0df70abec6f5e329d2d1841":{"links":[{"line":1,"link":"probabilistic normative models","original":"[[probabilistic normative models]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":6,"heading":"Resources","level":1}]},"d544e9fef0ada52bd3ba7293da713c5b74328e5b2e4b8f584eb72e6d7debe418":{"links":[],"embeds":[],"tags":[],"headings":[]},"4b7159856079be6ac2aef5aa3a5fe21a374a3d4fadd07c9fc9ce6addd7bbe571":{"links":[],"embeds":[],"tags":[],"headings":[]},"2096c413b8b6d3ce4e7347ce553ea92b4899573b1dc382dbf87d4a1940429478":{"links":[{"line":0,"link":"statistics","original":"[[statistics]]","displayText":"","beforeContext":"","afterContext":"random variableconditioningbayesian statistics"},{"line":0,"link":"random variable","original":"[[random variable]]","displayText":"","beforeContext":"statistics","afterContext":"conditioningbayesian statistics"},{"line":0,"link":"conditioning","original":"[[conditioning]]","displayText":"","beforeContext":"statisticsrandom variable","afterContext":"bayesian statistics"},{"line":0,"link":"bayesian statistics","original":"[[bayesian statistics]]","displayText":"","beforeContext":"statisticsrandom variableconditioning","afterContext":""},{"line":9,"link":"frequentist statistics","original":"[[frequentist statistics|Frequentist]]","displayText":"Frequentist","beforeContext":"","afterContext":": Frequency of observed event"},{"line":12,"link":"product rule","original":"[[product rule|Product Rule]]","displayText":"Product Rule","beforeContext":"","afterContext":": If two events are independent, the probability of both is the product of each’s probability:"},{"line":12,"link":"probability","original":"[[probability]]","displayText":"","beforeContext":"Product Rule: If two events are independent, the ","afterContext":" of both is the product of each’s probability:"},{"line":16,"link":"sum rule","original":"[[sum rule|Sum Rule]]","displayText":"Sum Rule","beforeContext":"","afterContext":": If two events are mutually exclusive the probability of either is the sum of each’s probability:"}],"embeds":[{"line":22,"link":"Distributions.png","original":"![[Distributions.png]]","beforeContext":"","afterContext":""}],"tags":[],"headings":[{"line":6,"heading":"Notes","level":1},{"line":20,"heading":"Resources","level":1}]},"22cbf662d8a39647d2db85cf0b2f6f4d4e6da75d205f824530f1b61816a7ad2e":{"links":[{"line":0,"link":"statistics","original":"[[statistics]]","displayText":"","beforeContext":"","afterContext":"probabilitymodelingbayesian decision theory"},{"line":0,"link":"probability","original":"[[probability]]","displayText":"","beforeContext":"statistics","afterContext":"modelingbayesian decision theory"},{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"statisticsprobability","afterContext":"bayesian decision theory"},{"line":0,"link":"bayesian decision theory","original":"[[bayesian decision theory]]","displayText":"","beforeContext":"statisticsprobabilitymodeling","afterContext":""},{"line":12,"link":"product rule","original":"[[product rule|product]]","displayText":"product","beforeContext":"Posterior is the ","afterContext":" of the prior and likelihood (normalized)"},{"line":13,"link":"sum rule","original":"[[sum rule|Sum rule]]","displayText":"Sum rule","beforeContext":"","afterContext":" used for normalizing"}],"embeds":[],"tags":[],"headings":[{"line":5,"heading":"Notes","level":1},{"line":15,"heading":"Resources","level":1}]},"53d55a94bc2f9b902c2c26d1759c8e5ca7a3a6985435898b07bd6ac24c1c9c01":{"links":[{"line":96,"link":"NMA Project Code","original":"[[NMA Project Code]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[{"line":2,"tag":"#neuromatch"}],"headings":[{"line":4,"heading":"Notes","level":1},{"line":15,"heading":"Group B","level":1},{"line":16,"heading":"Questions","level":3},{"line":29,"heading":"Mentor meeting","level":3},{"line":64,"heading":"Ideas","level":3},{"line":79,"heading":"Resources","level":1},{"line":80,"heading":"Papers","level":2},{"line":84,"heading":"Other","level":2},{"line":96,"heading":"[[NMA Project Code]]","level":1}]},"5943983e2f2fd7c89082bdcfd2b89a9121aad13d0b31bc78bf9a48e9b8006dcf":{"links":[],"embeds":[],"tags":[],"headings":[{"line":0,"heading":"Sequence","level":1}]},"d99cecc80257e3b4b1a7a96290b74eac69553a29941501a02c95c06f135df1e6":{"links":[{"line":1,"link":"Fourier transform","original":"[[Fourier transform]]","displayText":"","beforeContext":"","afterContext":"fast Fourier transformdimensionality reductionlinear algebra"},{"line":1,"link":"fast Fourier transform","original":"[[fast Fourier transform]]","displayText":"","beforeContext":"Fourier transform","afterContext":"dimensionality reductionlinear algebra"},{"line":1,"link":"dimensionality reduction","original":"[[dimensionality reduction]]","displayText":"","beforeContext":"Fourier transformfast Fourier transform","afterContext":"linear algebra"},{"line":1,"link":"linear algebra","original":"[[linear algebra]]","displayText":"","beforeContext":"Fourier transformfast Fourier transformdimensionality reduction","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":7,"heading":"Notes","level":1},{"line":13,"heading":"Resources","level":1}]},"b20e052a97acd9f74d7016d094eba807a973df079fc09238c04f4832673060f7":{"links":[{"line":0,"link":"eigenvectors","original":"[[eigenvectors]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[],"headings":[]},"c990790b6849f94aee8ae50b8fdde77518b4cb9a5e11fc266caa1967ae6d82d6":{"links":[{"line":0,"link":"linear dynamical system","original":"[[linear dynamical system]]","displayText":"","beforeContext":"","afterContext":""},{"line":8,"link":"linear dynamical system","original":"[[linear dynamical system]]","displayText":"","beforeContext":"Basic Equation for ","afterContext":":"}],"embeds":[],"tags":[],"headings":[{"line":2,"heading":"Notes","level":1},{"line":16,"heading":"Resources","level":1}]},"76767e86e06aac54b2845fd13e4a51051e6c2ca104db38fee3e6712344668992":{"links":[{"line":0,"link":"probability","original":"[[probability]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":2,"heading":"Notes","level":1},{"line":17,"heading":"Resources","level":1}]},"3f4acb007391a4d272c9864afb367b14dc5c3661e220972a927a909782b1a610":{"links":[{"line":0,"link":"Brownian motion","original":"[[Brownian motion]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":4,"heading":"Notes","level":1},{"line":6,"heading":"Resources","level":1}]},"0782d166060c686df1a7b3738da0a3fda5935cafd8656c382f6e7621db407d6d":{"links":[{"line":0,"link":"random walk","original":"[[random walk]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":6,"heading":"Resources","level":1}]},"f301373c58fabe542f41661e4ef9f08541949ebdb31f0b0cab948fc2febe46e1":{"links":[],"embeds":[],"tags":[],"headings":[]},"9a5ab37858b47053b7c06c182d2a8d56cb9e8a45e58c2a410713409cfb3ed9db":{"links":[{"line":0,"link":"linear algebra","original":"[[linear algebra]]","displayText":"","beforeContext":"","afterContext":"vectors"},{"line":0,"link":"vectors","original":"[[vectors]]","displayText":"","beforeContext":"linear algebra","afterContext":""}],"embeds":[{"line":10,"link":"scaling_by_basis_vectors.png","original":"![[scaling_by_basis_vectors.png]]","beforeContext":"Scaling by basis vectors:","afterContext":""}],"tags":[],"headings":[{"line":4,"heading":"Notes","level":1},{"line":13,"heading":"Resources","level":1}]},"79eed58abc3fd882d78833e6694a3efe07322b05649f86623dde4fe8b70c4c2e":{"links":[{"line":0,"link":"Ornstein-Uhlenbeck process","original":"[[Ornstein-Uhlenbeck process]]","displayText":"","beforeContext":"","afterContext":""},{"line":6,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"Collab NotebookCollab Notebook from ","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":2,"heading":"Notes","level":1},{"line":5,"heading":"Resources","level":1}]},"060863b77be24b886b56504e975ff9919e1217081d3ce4866892ce3bc228b270":{"links":[{"line":0,"link":"drift diffusion","original":"[[drift diffusion]]","displayText":"","beforeContext":"","afterContext":""},{"line":6,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"Colab NotebookColab Notebook from ","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":2,"heading":"Notes","level":1},{"line":5,"heading":"Resources","level":1}]},"90420837ea741b56a5af9a4ea3aff439a8be6b3d5bda43c0ffbeefbdb4cdac50":{"links":[{"line":0,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"","afterContext":"dynamical systemseigenvectorseigenvaluesattractorsrandom walkBrownian motiondrift diffusionOrnstein-Uhlenbeck processLFADSKalman filter"},{"line":0,"link":"dynamical systems","original":"[[dynamical systems]]","displayText":"","beforeContext":"Neuromatch","afterContext":"eigenvectorseigenvaluesattractorsrandom walkBrownian motiondrift diffusionOrnstein-Uhlenbeck processLFADSKalman filter"},{"line":0,"link":"eigenvectors","original":"[[eigenvectors]]","displayText":"","beforeContext":"Neuromatchdynamical systems","afterContext":"eigenvaluesattractorsrandom walkBrownian motiondrift diffusionOrnstein-Uhlenbeck processLFADSKalman filter"},{"line":0,"link":"eigenvalues","original":"[[eigenvalues]]","displayText":"","beforeContext":"Neuromatchdynamical systemseigenvectors","afterContext":"attractorsrandom walkBrownian motiondrift diffusionOrnstein-Uhlenbeck processLFADSKalman filter"},{"line":0,"link":"attractors","original":"[[attractors]]","displayText":"","beforeContext":"Neuromatchdynamical systemseigenvectorseigenvalues","afterContext":"random walkBrownian motiondrift diffusionOrnstein-Uhlenbeck processLFADSKalman filter"},{"line":0,"link":"random walk","original":"[[random walk]]","displayText":"","beforeContext":"Neuromatchdynamical systemseigenvectorseigenvaluesattractors","afterContext":"Brownian motiondrift diffusionOrnstein-Uhlenbeck processLFADSKalman filter"},{"line":0,"link":"Brownian motion","original":"[[Brownian motion]]","displayText":"","beforeContext":"Neuromatchdynamical systemseigenvectorseigenvaluesattractorsrandom walk","afterContext":"drift diffusionOrnstein-Uhlenbeck processLFADSKalman filter"},{"line":0,"link":"drift diffusion","original":"[[drift diffusion]]","displayText":"","beforeContext":"Neuromatchdynamical systemseigenvectorseigenvaluesattractorsrandom walkBrownian motion","afterContext":"Ornstein-Uhlenbeck processLFADSKalman filter"},{"line":0,"link":"Ornstein-Uhlenbeck process","original":"[[Ornstein-Uhlenbeck process]]","displayText":"","beforeContext":"Neuromatchdynamical systemseigenvectorseigenvaluesattractorsrandom walkBrownian motiondrift diffusion","afterContext":"LFADSKalman filter"},{"line":0,"link":"LFADS","original":"[[LFADS]]","displayText":"","beforeContext":"Neuromatchdynamical systemseigenvectorseigenvaluesattractorsrandom walkBrownian motiondrift diffusionOrnstein-Uhlenbeck process","afterContext":"Kalman filter"},{"line":0,"link":"Kalman filter","original":"[[Kalman filter]]","displayText":"","beforeContext":"Neuromatchdynamical systemseigenvectorseigenvaluesattractorsrandom walkBrownian motiondrift diffusionOrnstein-Uhlenbeck processLFADS","afterContext":""},{"line":14,"link":"dynamical systems","original":"[[dynamical systems|Dynamical system]]","displayText":"Dynamical system","beforeContext":"","afterContext":" has a trajectory through multi-dimensional space"},{"line":15,"link":"Hodkin & Huxley model","original":"[[Hodkin & Huxley model]]","displayText":"","beforeContext":"","afterContext":": dynamics of spike generation"},{"line":16,"link":"Nobel prize","original":"[[Nobel prize]]","displayText":"","beforeContext":"won the ","afterContext":""},{"line":25,"link":"leaky competing accumulator","original":"[[leaky competing accumulator|Leaky, Competing Accumulator]]","displayText":"Leaky, Competing Accumulator","beforeContext":"Paper: Usher & McClelland 2001: The Time Course of Perceptual Choice: The ","afterContext":" Model"}],"embeds":[],"tags":[],"headings":[{"line":12,"heading":"Linear Systems","level":1},{"line":20,"heading":"Takeaways","level":1},{"line":24,"heading":"Resources","level":1}]},"04ea3179db29fcc6eadf66a2586692b8b78e413d684d7aee02c9fcdf105b3aed":{"links":[{"line":0,"link":"graphical models","original":"[[graphical models]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[],"headings":[]},"9c15e9d2ee73167bb1f7878a2c1ca03447a47c97414c943f3838c10a237fb3d7":{"links":[{"line":0,"link":"gaussian distribution","original":"[[gaussian distribution]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[],"headings":[]},"66f7f6eb87c32e8ccc66211c2441ddf860556295fc3a9e31ec0bbd107c6dd4dc":{"links":[],"embeds":[],"tags":[],"headings":[]},"5fd426b6b9062d77accecfd7676d4d96c6e305accaa5ed19b58c245c49fccec7":{"links":[],"embeds":[],"tags":[],"headings":[]},"fc820c8905676b665b7c516ee2f2133364f112716dab60ffed7ea6c544ce3d89":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"model fittinggeneral linear modelpoisson glmhyperparametersregularizationencoding modeldecoding modellogistic regressionoverfittingcoupled glmbasis function"},{"line":0,"link":"model fitting","original":"[[model fitting]]","displayText":"","beforeContext":"modeling","afterContext":"general linear modelpoisson glmhyperparametersregularizationencoding modeldecoding modellogistic regressionoverfittingcoupled glmbasis function"},{"line":0,"link":"general linear model","original":"[[general linear model]]","displayText":"","beforeContext":"modelingmodel fitting","afterContext":"poisson glmhyperparametersregularizationencoding modeldecoding modellogistic regressionoverfittingcoupled glmbasis function"},{"line":0,"link":"poisson glm","original":"[[poisson glm]]","displayText":"","beforeContext":"modelingmodel fittinggeneral linear model","afterContext":"hyperparametersregularizationencoding modeldecoding modellogistic regressionoverfittingcoupled glmbasis function"},{"line":0,"link":"hyperparameters","original":"[[hyperparameters]]","displayText":"","beforeContext":"modelingmodel fittinggeneral linear modelpoisson glm","afterContext":"regularizationencoding modeldecoding modellogistic regressionoverfittingcoupled glmbasis function"},{"line":0,"link":"regularization","original":"[[regularization]]","displayText":"","beforeContext":"modelingmodel fittinggeneral linear modelpoisson glmhyperparameters","afterContext":"encoding modeldecoding modellogistic regressionoverfittingcoupled glmbasis function"},{"line":0,"link":"encoding model","original":"[[encoding model]]","displayText":"","beforeContext":"modelingmodel fittinggeneral linear modelpoisson glmhyperparametersregularization","afterContext":"decoding modellogistic regressionoverfittingcoupled glmbasis function"},{"line":0,"link":"decoding model","original":"[[decoding model]]","displayText":"","beforeContext":"modelingmodel fittinggeneral linear modelpoisson glmhyperparametersregularizationencoding model","afterContext":"logistic regressionoverfittingcoupled glmbasis function"},{"line":0,"link":"logistic regression","original":"[[logistic regression]]","displayText":"","beforeContext":"modelingmodel fittinggeneral linear modelpoisson glmhyperparametersregularizationencoding modeldecoding model","afterContext":"overfittingcoupled glmbasis function"},{"line":0,"link":"overfitting","original":"[[overfitting]]","displayText":"","beforeContext":"modelingmodel fittinggeneral linear modelpoisson glmhyperparametersregularizationencoding modeldecoding modellogistic regression","afterContext":"coupled glmbasis function"},{"line":0,"link":"coupled glm","original":"[[coupled glm]]","displayText":"","beforeContext":"modelingmodel fittinggeneral linear modelpoisson glmhyperparametersregularizationencoding modeldecoding modellogistic regressionoverfitting","afterContext":"basis function"},{"line":0,"link":"basis function","original":"[[basis function]]","displayText":"","beforeContext":"modelingmodel fittinggeneral linear modelpoisson glmhyperparametersregularizationencoding modeldecoding modellogistic regressionoverfittingcoupled glm","afterContext":""},{"line":27,"link":"general linear model","original":"[[general linear model|GLMs]]","displayText":"GLMs","beforeContext":"If your problem can be posed as a regression or classification use ","afterContext":" first!"},{"line":28,"link":"general linear model","original":"[[general linear model|GLM]]","displayText":"GLM","beforeContext":"","afterContext":" weights do not imply causal relationships!"},{"line":28,"link":"causality","original":"[[causality|causal]]","displayText":"causal","beforeContext":"GLM weights do not imply ","afterContext":" relationships!"}],"embeds":[],"tags":[{"line":13,"tag":"#neuromatch"}],"headings":[{"line":15,"heading":"Generalized Linear Models","level":1},{"line":25,"heading":"Take Aways","level":1},{"line":32,"heading":"Resources","level":1}]},"82f97a23370aa4a37eac049dafb2d89447688955c447a5e4e2cdbb4704648bc7":{"links":[{"line":5,"link":"Pearl_J","original":"[[Pearl_J]]","displayText":"","beforeContext":"Book: /Users/djw/Documents/pCloud_synced/Academics/Books/Judea_Pearl_and_Dana_Mackenzie_The_Book.pdf ","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":2,"heading":"Notes","level":1},{"line":4,"heading":"Resources","level":1}]},"181414448b05efa2b21ab55eb0b5b70ea5468cc95ccae69b4d03fe0ea58a3ce1":{"links":[{"line":3,"link":"Bishop_CM","original":"[[Bishop_CM]]","displayText":"","beforeContext":"Book: /Users/djw/Documents/pCloud_synced/Academics/Books/Pattern Recognition And Machine Learning - Bishop  2006.pdf ","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":0,"heading":"Notes","level":1},{"line":2,"heading":"Resources","level":1}]},"22ca4ba99821dd779474b811cac2e45ea3c3b5d200f38f77c2c62a231948ce94":{"links":[],"embeds":[],"tags":[],"headings":[{"line":2,"heading":"Notes","level":1},{"line":4,"heading":"Resources","level":1}]},"afe56c89acbae851e6ce8c515d0dd8db461bec5984d4c0c744916237e75d90f1":{"links":[],"embeds":[],"tags":[],"headings":[]},"30f5ecd4250f6d99690be12a590a96e5e169a89c52660bbb15bda5174e775d58":{"links":[],"embeds":[],"tags":[],"headings":[]},"28cae562d268f1b11514fdb03c4e884d57bf266b68a18beb4800f6ab93fd967e":{"links":[],"embeds":[],"tags":[],"headings":[]},"c131c6a2d71f91557d446bac91eecf0f284ea5bf60e1f0390d9c9b3a4f78ac16":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"entropy"},{"line":0,"link":"entropy","original":"[[entropy]]","displayText":"","beforeContext":"modeling","afterContext":""},{"line":16,"link":"optimization","original":"[[optimization|optimization]]","displayText":"","beforeContext":"how to think about ","afterContext":""},{"line":17,"link":"Ecological validity","original":"[[Ecological validity|ecological validity]]","displayText":"ecological validity","beforeContext":"","afterContext":""},{"line":34,"link":"Exponential distribution","original":"[[Exponential distribution|exponential]]","displayText":"exponential","beforeContext":"ISI histograms look ","afterContext":""},{"line":37,"link":"entropy","original":"[[entropy]]","displayText":"","beforeContext":"","afterContext":""},{"line":45,"link":"Claude Shannon","original":"[[Claude Shannon]]","displayText":"","beforeContext":"","afterContext":"’s foundational 1948 paper1948 paper on information theory."},{"line":45,"link":"Information Theory","original":"[[Information Theory|information theory]]","displayText":"information theory","beforeContext":"Claude Shannon’s foundational 1948 paper1948 paper on ","afterContext":"."}],"embeds":[],"tags":[{"line":3,"tag":"#neuromatch"}],"headings":[{"line":5,"heading":"Model Types","level":1},{"line":6,"heading":"Levels of Analysis","level":2},{"line":19,"heading":"Section 1: What Models","level":2},{"line":25,"heading":"Section 2: How Models","level":2},{"line":29,"heading":"Section 3: Why Models","level":2},{"line":33,"heading":"Take aways","level":1},{"line":40,"heading":"Resources","level":1}]},"0a1d6deb390dd20e10f8dd50cc63f0c2b5bcac33580e8b884b0b1aad40c5f509":{"links":[{"line":0,"link":"autoregressive glm","original":"[[autoregressive glm]]","displayText":"","beforeContext":"","afterContext":""},{"line":6,"link":"optimization","original":"[[optimization]]","displayText":"","beforeContext":"Convexity of ","afterContext":""},{"line":10,"link":"regularization","original":"[[regularization|Regularize!]]","displayText":"Regularize!","beforeContext":"","afterContext":""}],"embeds":[{"line":12,"link":"glms .png","original":"![[glms .png]]","beforeContext":"","afterContext":""}],"tags":[],"headings":[{"line":2,"heading":"Notes","level":1},{"line":17,"heading":"Resources","level":1}]},"c7819d70854b134aa01d5bba392f5c29b4db011a0ea3f5a6d041cbd5fbb45432":{"links":[{"line":0,"link":"optimal control","original":"[[optimal control]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":2,"heading":"Notes","level":1},{"line":4,"heading":"Resources","level":1}]},"3b09085d25ce100e00c7f1311e745900997d2425bb42a2e730ab7f2b907a180d":{"links":[],"embeds":[],"tags":[],"headings":[]},"b8e79310203cbe1f757b357fe8e2e5aa290545cad7c240e16abec05c041f435f":{"links":[],"embeds":[],"tags":[],"headings":[]},"df663e27f496f8af839a7ce688a3dc061e503c601b3957a94b902e5877ad59c0":{"links":[{"line":0,"link":"optimization","original":"[[optimization]]","displayText":"","beforeContext":"","afterContext":"open loop control"},{"line":0,"link":"open loop control","original":"[[open loop control]]","displayText":"","beforeContext":"optimization","afterContext":""},{"line":6,"link":"closed loop control","original":"[[closed loop control]]","displayText":"","beforeContext":"","afterContext":" allows for feedbackExample of control:"}],"embeds":[{"line":6,"link":"control_problem_example.png","original":"![[control_problem_example.png]]","beforeContext":"closed loop control allows for feedbackExample of control:","afterContext":""}],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":11,"heading":"Resources","level":1}]},"aa521c4244191dec3282d636cc7a07e74953170406700f644167804606b2b7ce":{"links":[],"embeds":[],"tags":[],"headings":[]},"eb34c12ddb5154f04a241e5b6899970f65cb81eebc3441d0885479781b2e87a0":{"links":[],"embeds":[],"tags":[],"headings":[]},"fa0ba43697d215ef316f5fc57a7377c9bf69b3e635d139a37091962e6f9b9daf":{"links":[],"embeds":[],"tags":[],"headings":[]},"9f73e4d7ef3ab6494db7af076ba4fcf402063ae01fba4e9a4be2edd2ccdedd7c":{"links":[],"embeds":[{"line":5,"link":"bellman_equation.png","original":"![[bellman_equation.png]]","beforeContext":"Equation:","afterContext":""}],"tags":[],"headings":[{"line":2,"heading":"Notes","level":1},{"line":8,"heading":"Resources","level":1}]},"c3a591955aed6b56a6042a536a9efff5a8aae819a5cad4c945b76de1aab9c077":{"links":[{"line":4,"link":"meta-learning","original":"[[meta-learning]]","displayText":"","beforeContext":"","afterContext":"reinforcement learningMatthew Botvinick"},{"line":4,"link":"reinforcement learning","original":"[[reinforcement learning]]","displayText":"","beforeContext":"meta-learning","afterContext":"Matthew Botvinick"},{"line":4,"link":"Matthew Botvinick","original":"[[Matthew Botvinick]]","displayText":"","beforeContext":"meta-learningreinforcement learning","afterContext":""}],"embeds":[],"tags":[{"line":1,"tag":"#video"},{"line":1,"tag":"#labmeeting"},{"line":1,"tag":"#talk"}],"headings":[{"line":0,"heading":"Matthew Botvinick - Meta-learning in brains and machines","level":1},{"line":3,"heading":"Topics","level":2},{"line":8,"heading":"Notes","level":2},{"line":9,"heading":"Summary","level":3},{"line":21,"heading":"Thoughts","level":3},{"line":32,"heading":"Resources","level":2}]},"0a6b395e9750b3c0146f3faf1dcd50c6bb048e477b6924eba799ded5c885ccf1":{"links":[{"line":9,"link":"reinforcement learning","original":"[[reinforcement learning]]","displayText":"","beforeContext":"","afterContext":""},{"line":10,"link":"Dopamine","original":"[[Dopamine]]","displayText":"","beforeContext":"","afterContext":""},{"line":11,"link":"Perceptual decision","original":"[[Perceptual decision]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[{"line":4,"tag":"#paper"}],"headings":[{"line":0,"heading":"Info","level":1},{"line":14,"heading":"Notes","level":1},{"line":15,"heading":"Summary","level":2},{"line":18,"heading":"Thoughts","level":2},{"line":21,"heading":"Resources","level":1}]},"3fa208eda146ccab3f15f4c32a4420d6a23c4d8a703b9ba01a1b46212d479d6c":{"links":[{"line":0,"link":"modeling","original":"[[modeling]]","displayText":"","beforeContext":"","afterContext":"Levels of Analysis"},{"line":0,"link":"Levels of Analysis","original":"[[Levels of Analysis]]","displayText":"","beforeContext":"modeling","afterContext":""},{"line":9,"link":"Occam's Razor","original":"[[Occam's Razor]]","displayText":"Occam’s Razor","beforeContext":"Keep it as simple as possible, but as detailed as needed ","afterContext":""},{"line":18,"link":"Levels of Analysis","original":"[[Levels of Analysis]]","displayText":"","beforeContext":"","afterContext":""},{"line":27,"link":"Technology","original":"[[Technology|technologies]]","displayText":"technologies","beforeContext":"Inspire new ","afterContext":" /application"},{"line":33,"link":"neuroscience","original":"[[neuroscience]]","displayText":"","beforeContext":"","afterContext":""},{"line":34,"link":"Cosine tuning model","original":"[[Cosine tuning model]]","displayText":"","beforeContext":"","afterContext":" of neuronal activity"},{"line":35,"link":"Hodkin & Huxley model","original":"[[Hodkin & Huxley model| Hodkin & Huxley]]","displayText":"Hodkin & Huxley","beforeContext":"","afterContext":" single neuron spike generation model"},{"line":36,"link":"reinforcement learning","original":"[[reinforcement learning| Reinforcement learning]]","displayText":"Reinforcement learning","beforeContext":"","afterContext":" model"},{"line":43,"link":"Marr's 3 levels of analysis","original":"[[Marr's 3 levels of analysis]]","displayText":"Marr’s 3 levels of analysis","beforeContext":"","afterContext":""}],"embeds":[{"line":30,"link":"model_values.png","original":"![[model_values.png]]","beforeContext":"","afterContext":""},{"line":44,"link":"modeling_process.png","original":"![[modeling_process.png]]","beforeContext":"Modeling process: ","afterContext":""}],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":4,"heading":"Definition","level":2},{"line":20,"heading":"Uses","level":2},{"line":29,"heading":"Types","level":2},{"line":32,"heading":"Examples","level":2},{"line":33,"heading":"[[neuroscience]]","level":3},{"line":38,"heading":"Papers","level":4},{"line":42,"heading":"Resources","level":1}]},"79161d7450159c534452db43dacf3d4f13d0b1730d7a8eda45c5b114165796e6":{"links":[{"line":0,"link":"Bellman equation","original":"[[Bellman equation]]","displayText":"","beforeContext":"","afterContext":"optimal controlreinforcement learning"},{"line":0,"link":"optimal control","original":"[[optimal control]]","displayText":"","beforeContext":"Bellman equation","afterContext":"reinforcement learning"},{"line":0,"link":"reinforcement learning","original":"[[reinforcement learning]]","displayText":"","beforeContext":"Bellman equationoptimal control","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":4,"heading":"Notes","level":1},{"line":6,"heading":"Resources","level":1}]},"b68d54767640711b4c47d4e64229a8b838b3a76efd2969671c9d129b6506bc67":{"links":[{"line":20,"link":"hidden markov model","original":"[[hidden markov model]]","displayText":"","beforeContext":"Combined ","afterContext":" (HMMs) with GLMs"},{"line":20,"link":"general linear model","original":"[[general linear model|GLMs]]","displayText":"GLMs","beforeContext":"Combined hidden markov model (HMMs) with ","afterContext":""}],"embeds":[],"tags":[{"line":5,"tag":"#paper"},{"line":5,"tag":"#neuromatch"}],"headings":[{"line":0,"heading":"Info","level":1},{"line":13,"heading":"Notes","level":1},{"line":14,"heading":"Summary","level":2},{"line":23,"heading":"Thoughts","level":2},{"line":26,"heading":"Resources","level":1}]},"48eee0323346fe661fead40c3586b6be508cb9284dbfa8b0d5fe53d65fe311f0":{"links":[{"line":0,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"","afterContext":"hidden stateshidden markov modelcategorical distributionpoisson distributionbayes rulechain rulemarginalizationconditional independencegraphical modelsparametric modellog-likelihoodlinear dynamical systemmaximum likelihood estimatemultivariate gaussian distribution"},{"line":0,"link":"hidden states","original":"[[hidden states]]","displayText":"","beforeContext":"Neuromatch","afterContext":"hidden markov modelcategorical distributionpoisson distributionbayes rulechain rulemarginalizationconditional independencegraphical modelsparametric modellog-likelihoodlinear dynamical systemmaximum likelihood estimatemultivariate gaussian distribution"},{"line":0,"link":"hidden markov model","original":"[[hidden markov model]]","displayText":"","beforeContext":"Neuromatchhidden states","afterContext":"categorical distributionpoisson distributionbayes rulechain rulemarginalizationconditional independencegraphical modelsparametric modellog-likelihoodlinear dynamical systemmaximum likelihood estimatemultivariate gaussian distribution"},{"line":0,"link":"categorical distribution","original":"[[categorical distribution]]","displayText":"","beforeContext":"Neuromatchhidden stateshidden markov model","afterContext":"poisson distributionbayes rulechain rulemarginalizationconditional independencegraphical modelsparametric modellog-likelihoodlinear dynamical systemmaximum likelihood estimatemultivariate gaussian distribution"},{"line":0,"link":"poisson distribution","original":"[[poisson distribution]]","displayText":"","beforeContext":"Neuromatchhidden stateshidden markov modelcategorical distribution","afterContext":"bayes rulechain rulemarginalizationconditional independencegraphical modelsparametric modellog-likelihoodlinear dynamical systemmaximum likelihood estimatemultivariate gaussian distribution"},{"line":0,"link":"bayes rule","original":"[[bayes rule]]","displayText":"","beforeContext":"Neuromatchhidden stateshidden markov modelcategorical distributionpoisson distribution","afterContext":"chain rulemarginalizationconditional independencegraphical modelsparametric modellog-likelihoodlinear dynamical systemmaximum likelihood estimatemultivariate gaussian distribution"},{"line":0,"link":"chain rule","original":"[[chain rule]]","displayText":"","beforeContext":"Neuromatchhidden stateshidden markov modelcategorical distributionpoisson distributionbayes rule","afterContext":"marginalizationconditional independencegraphical modelsparametric modellog-likelihoodlinear dynamical systemmaximum likelihood estimatemultivariate gaussian distribution"},{"line":0,"link":"marginalization","original":"[[marginalization]]","displayText":"","beforeContext":"Neuromatchhidden stateshidden markov modelcategorical distributionpoisson distributionbayes rulechain rule","afterContext":"conditional independencegraphical modelsparametric modellog-likelihoodlinear dynamical systemmaximum likelihood estimatemultivariate gaussian distribution"},{"line":0,"link":"conditional independence","original":"[[conditional independence]]","displayText":"","beforeContext":"Neuromatchhidden stateshidden markov modelcategorical distributionpoisson distributionbayes rulechain rulemarginalization","afterContext":"graphical modelsparametric modellog-likelihoodlinear dynamical systemmaximum likelihood estimatemultivariate gaussian distribution"},{"line":0,"link":"graphical models","original":"[[graphical models]]","displayText":"","beforeContext":"Neuromatchhidden stateshidden markov modelcategorical distributionpoisson distributionbayes rulechain rulemarginalizationconditional independence","afterContext":"parametric modellog-likelihoodlinear dynamical systemmaximum likelihood estimatemultivariate gaussian distribution"},{"line":0,"link":"parametric model","original":"[[parametric model]]","displayText":"","beforeContext":"Neuromatchhidden stateshidden markov modelcategorical distributionpoisson distributionbayes rulechain rulemarginalizationconditional independencegraphical models","afterContext":"log-likelihoodlinear dynamical systemmaximum likelihood estimatemultivariate gaussian distribution"},{"line":0,"link":"log-likelihood","original":"[[log-likelihood]]","displayText":"","beforeContext":"Neuromatchhidden stateshidden markov modelcategorical distributionpoisson distributionbayes rulechain rulemarginalizationconditional independencegraphical modelsparametric model","afterContext":"linear dynamical systemmaximum likelihood estimatemultivariate gaussian distribution"},{"line":0,"link":"linear dynamical system","original":"[[linear dynamical system]]","displayText":"","beforeContext":"Neuromatchhidden stateshidden markov modelcategorical distributionpoisson distributionbayes rulechain rulemarginalizationconditional independencegraphical modelsparametric modellog-likelihood","afterContext":"maximum likelihood estimatemultivariate gaussian distribution"},{"line":0,"link":"maximum likelihood estimate","original":"[[maximum likelihood estimate]]","displayText":"","beforeContext":"Neuromatchhidden stateshidden markov modelcategorical distributionpoisson distributionbayes rulechain rulemarginalizationconditional independencegraphical modelsparametric modellog-likelihoodlinear dynamical system","afterContext":"multivariate gaussian distribution"},{"line":0,"link":"multivariate gaussian distribution","original":"[[multivariate gaussian distribution]]","displayText":"","beforeContext":"Neuromatchhidden stateshidden markov modelcategorical distributionpoisson distributionbayes rulechain rulemarginalizationconditional independencegraphical modelsparametric modellog-likelihoodlinear dynamical systemmaximum likelihood estimate","afterContext":""},{"line":29,"link":"Kalman filter","original":"[[Kalman filter|Kalman filters]]","displayText":"Kalman filters","beforeContext":"","afterContext":" optimal for state decoding/inference"}],"embeds":[],"tags":[{"line":16,"tag":"#neuromatch"}],"headings":[{"line":18,"heading":"Decision Making","level":1},{"line":28,"heading":"Takeaways","level":1},{"line":31,"heading":"Resources","level":1}]},"9b1e21314885b648babc75a7796174cef3559a6c28e960123055ea5b2d583eac":{"links":[{"line":0,"link":"Kalman filter","original":"[[Kalman filter]]","displayText":"","beforeContext":"","afterContext":"hidden markov model"},{"line":0,"link":"hidden markov model","original":"[[hidden markov model]]","displayText":"","beforeContext":"Kalman filter","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":4,"heading":"Notes","level":1},{"line":6,"heading":"Resources","level":1}]},"23c558c3ab6d4991bfe246c88069e546d5cbce4b3ca5e77e860caa48a5a9b17d":{"links":[{"line":1,"link":"bayesian statistics","original":"[[bayesian statistics]]","displayText":"","beforeContext":"","afterContext":"statisticsnormative modelsMarr’s 3 levels of analysislatent variablesinferenceutilitydecisionprobabilistic graphical modelsmarkov decision process"},{"line":1,"link":"statistics","original":"[[statistics]]","displayText":"","beforeContext":"bayesian statistics","afterContext":"normative modelsMarr’s 3 levels of analysislatent variablesinferenceutilitydecisionprobabilistic graphical modelsmarkov decision process"},{"line":1,"link":"normative models","original":"[[normative models]]","displayText":"","beforeContext":"bayesian statisticsstatistics","afterContext":"Marr’s 3 levels of analysislatent variablesinferenceutilitydecisionprobabilistic graphical modelsmarkov decision process"},{"line":1,"link":"Marr's 3 levels of analysis","original":"[[Marr's 3 levels of analysis]]","displayText":"Marr’s 3 levels of analysis","beforeContext":"bayesian statisticsstatisticsnormative models","afterContext":"latent variablesinferenceutilitydecisionprobabilistic graphical modelsmarkov decision process"},{"line":1,"link":"latent variables","original":"[[latent variables]]","displayText":"","beforeContext":"bayesian statisticsstatisticsnormative modelsMarr’s 3 levels of analysis","afterContext":"inferenceutilitydecisionprobabilistic graphical modelsmarkov decision process"},{"line":1,"link":"inference","original":"[[inference]]","displayText":"","beforeContext":"bayesian statisticsstatisticsnormative modelsMarr’s 3 levels of analysislatent variables","afterContext":"utilitydecisionprobabilistic graphical modelsmarkov decision process"},{"line":1,"link":"utility","original":"[[utility]]","displayText":"","beforeContext":"bayesian statisticsstatisticsnormative modelsMarr’s 3 levels of analysislatent variablesinference","afterContext":"decisionprobabilistic graphical modelsmarkov decision process"},{"line":1,"link":"decision","original":"[[decision]]","displayText":"","beforeContext":"bayesian statisticsstatisticsnormative modelsMarr’s 3 levels of analysislatent variablesinferenceutility","afterContext":"probabilistic graphical modelsmarkov decision process"},{"line":1,"link":"probabilistic graphical models","original":"[[probabilistic graphical models]]","displayText":"","beforeContext":"bayesian statisticsstatisticsnormative modelsMarr’s 3 levels of analysislatent variablesinferenceutilitydecision","afterContext":"markov decision process"},{"line":1,"link":"markov decision process","original":"[[markov decision process]]","displayText":"","beforeContext":"bayesian statisticsstatisticsnormative modelsMarr’s 3 levels of analysislatent variablesinferenceutilitydecisionprobabilistic graphical models","afterContext":""},{"line":14,"link":"normative models","original":"[[normative models|Normative models]]","displayText":"Normative models","beforeContext":"General Motivation: ","afterContext":""},{"line":17,"link":"variables","original":"[[variables|Variables]]","displayText":"Variables","beforeContext":"","afterContext":""},{"line":18,"link":"probability","original":"[[probability|Probability]]","displayText":"Probability","beforeContext":"","afterContext":""},{"line":19,"link":"inference","original":"[[inference|Inference]]","displayText":"Inference","beforeContext":"","afterContext":""}],"embeds":[{"line":23,"link":"bayes_rule.png","original":"![[bayes_rule.png]]","beforeContext":"","afterContext":""}],"tags":[],"headings":[{"line":13,"heading":"Bayesian Statistics","level":1},{"line":39,"heading":"Take Aways","level":1},{"line":49,"heading":"Resources","level":1}]},"94f86ae844ccec7e9f88d12c753bec9c08091bc5d7e4c12032aff7f0167d2cf2":{"links":[{"line":0,"link":"hidden markov model","original":"[[hidden markov model]]","displayText":"","beforeContext":"","afterContext":""},{"line":10,"link":"markov decision process","original":"[[markov decision process|Markovian]]","displayText":"Markovian","beforeContext":"Can restrict dynamics to ","afterContext":" systems."}],"embeds":[{"line":8,"link":"hidden_state_models.png","original":"![[hidden_state_models.png]]","beforeContext":"","afterContext":""}],"tags":[],"headings":[{"line":2,"heading":"Notes","level":1},{"line":13,"heading":"Resources","level":1}]},"4591473e226672ba311f6645bc655b45120fb71acce78f22a1b41d79040905e5":{"links":[{"line":0,"link":"markov decision process","original":"[[markov decision process]]","displayText":"","beforeContext":"","afterContext":"linear dynamical systemlatent state"},{"line":0,"link":"linear dynamical system","original":"[[linear dynamical system]]","displayText":"","beforeContext":"markov decision process","afterContext":"latent state"},{"line":0,"link":"latent state","original":"[[latent state]]","displayText":"","beforeContext":"markov decision processlinear dynamical system","afterContext":""},{"line":5,"link":"hidden markov model","original":"[[hidden markov model]]","displayText":"","beforeContext":"A ","afterContext":""},{"line":20,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"Colab notebookColab notebook from ","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":4,"heading":"Notes","level":1},{"line":19,"heading":"Resources","level":1}]},"519086699975061d92a9575f129acea5be3a8dd00642b168a99a2d46823619b4":{"links":[{"line":0,"link":"markov decision process","original":"[[markov decision process]]","displayText":"","beforeContext":"","afterContext":"hidden markov model"},{"line":0,"link":"hidden markov model","original":"[[hidden markov model]]","displayText":"","beforeContext":"markov decision process","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":4,"heading":"Notes","level":1},{"line":6,"heading":"Resources","level":1}]},"866fcb3a3554aefa80ffc573f53166cc9d02b9ca3613715584aa8282699bfdfa":{"links":[{"line":0,"link":"markov model","original":"[[markov model]]","displayText":"","beforeContext":"","afterContext":"markov decision processhidden statesKalman filter"},{"line":0,"link":"markov decision process","original":"[[markov decision process]]","displayText":"","beforeContext":"markov model","afterContext":"hidden statesKalman filter"},{"line":0,"link":"hidden states","original":"[[hidden states]]","displayText":"","beforeContext":"markov modelmarkov decision process","afterContext":"Kalman filter"},{"line":0,"link":"Kalman filter","original":"[[Kalman filter]]","displayText":"","beforeContext":"markov modelmarkov decision processhidden states","afterContext":""},{"line":7,"link":"conditional independence","original":"[[conditional independence]]","displayText":"","beforeContext":"","afterContext":""},{"line":8,"link":"transition matrix","original":"[[transition matrix]]","displayText":"","beforeContext":"Dynamics are the columns of the ","afterContext":""},{"line":9,"link":"Kalman filter","original":"[[Kalman filter]]","displayText":"","beforeContext":"HMM with continuous linear dynamics = ","afterContext":""},{"line":15,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"Video: ","afterContext":" introintro: w2d3"},{"line":15,"link":"w2d3","original":"[[w2d3]]","displayText":"","beforeContext":"Video: Neuromatch introintro: ","afterContext":""}],"embeds":[{"line":11,"link":"HMM_variants.png","original":"![[HMM_variants.png]]","beforeContext":"Some variants:","afterContext":""}],"tags":[],"headings":[{"line":5,"heading":"Notes","level":1},{"line":14,"heading":"Resources","level":1}]},"8fc47e0332bb99c85be301d02951b5ce03e92df38a9e525f3fe7a6e9f6a20dd7":{"links":[{"line":0,"link":"markov model","original":"[[markov model]]","displayText":"","beforeContext":"","afterContext":"markov decision processhidden markov model"},{"line":0,"link":"markov decision process","original":"[[markov decision process]]","displayText":"","beforeContext":"markov model","afterContext":"hidden markov model"},{"line":0,"link":"hidden markov model","original":"[[hidden markov model]]","displayText":"","beforeContext":"markov modelmarkov decision process","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":4,"heading":"Notes","level":1},{"line":6,"heading":"Resources","level":1}]},"ffc59213c6bd66036db5887090f78235a7f029e9c68d8d36732f4fb0808aac93":{"links":[{"line":0,"link":"hidden markov model","original":"[[hidden markov model]]","displayText":"","beforeContext":"","afterContext":"dynamical systems"},{"line":0,"link":"dynamical systems","original":"[[dynamical systems]]","displayText":"","beforeContext":"hidden markov model","afterContext":""},{"line":7,"link":"telegraph process","original":"[[telegraph process]]","displayText":"","beforeContext":"Two state Markov also known as ","afterContext":""},{"line":8,"link":"hidden markov model","original":"[[hidden markov model]]","displayText":"","beforeContext":"This is a binary ","afterContext":""},{"line":9,"link":"markov model","original":"[[markov model]]","displayText":"","beforeContext":"","afterContext":": Dynamical system with restricted dynamics"}],"embeds":[],"tags":[],"headings":[{"line":4,"heading":"Notes","level":1},{"line":12,"heading":"Resources","level":1}]},"75ecc92451ab05fedf31f8624c4719c907252152f464b4642f36f1a61b28ea61":{"links":[{"line":0,"link":"optimal control","original":"[[optimal control]]","displayText":"","beforeContext":"","afterContext":"optimizationclosed loop control"},{"line":0,"link":"optimization","original":"[[optimization]]","displayText":"","beforeContext":"optimal control","afterContext":"closed loop control"},{"line":0,"link":"closed loop control","original":"[[closed loop control]]","displayText":"","beforeContext":"optimal controloptimization","afterContext":""},{"line":6,"link":"partially observable markov decision process","original":"[[partially observable markov decision process]]","displayText":"","beforeContext":"Solves ","afterContext":" without measurements"}],"embeds":[{"line":6,"link":"open_loop_control_formula.png","original":"![[open_loop_control_formula.png]]","beforeContext":"Solves partially observable markov decision process without measurements","afterContext":""}],"tags":[],"headings":[{"line":5,"heading":"Notes","level":1},{"line":9,"heading":"Resources","level":1}]},"c1942996b3a698bea47e2557bfa8d043e4b2bad94503e52f612aa62df7c607e2":{"links":[{"line":0,"link":"optimal control","original":"[[optimal control]]","displayText":"","beforeContext":"","afterContext":"optimization"},{"line":0,"link":"optimization","original":"[[optimization]]","displayText":"","beforeContext":"optimal control","afterContext":""},{"line":4,"link":"partially observable markov decision process","original":"[[partially observable markov decision process]]","displayText":"","beforeContext":"Solves ","afterContext":" without measurements"}],"embeds":[{"line":6,"link":"closed_loop_control_formula.png","original":"![[closed_loop_control_formula.png]]","beforeContext":"Formula:","afterContext":""}],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":8,"heading":"Resources","level":1}]},"543ec5d23c68fa8bb8cea0790fecbf656bda6da50178efd6c88c5067cb34b84a":{"links":[{"line":0,"link":"Neuromatch","original":"[[Neuromatch]]","displayText":"","beforeContext":"","afterContext":"optimal controloptimizationopen loop controlclosed loop control\tcomputational neurosciencemarkov decision processBellman equationforaging theory"},{"line":0,"link":"optimal control","original":"[[optimal control]]","displayText":"","beforeContext":"Neuromatch","afterContext":"optimizationopen loop controlclosed loop control\tcomputational neurosciencemarkov decision processBellman equationforaging theory"},{"line":0,"link":"optimization","original":"[[optimization]]","displayText":"","beforeContext":"Neuromatchoptimal control","afterContext":"open loop controlclosed loop control\tcomputational neurosciencemarkov decision processBellman equationforaging theory"},{"line":0,"link":"open loop control","original":"[[open loop control]]","displayText":"","beforeContext":"Neuromatchoptimal controloptimization","afterContext":"closed loop control\tcomputational neurosciencemarkov decision processBellman equationforaging theory"},{"line":0,"link":"closed loop control","original":"[[closed loop control]]","displayText":"","beforeContext":"Neuromatchoptimal controloptimizationopen loop control","afterContext":"\tcomputational neurosciencemarkov decision processBellman equationforaging theory"},{"line":0,"link":"computational neuroscience","original":"[[computational neuroscience]]","displayText":"","beforeContext":"Neuromatchoptimal controloptimizationopen loop controlclosed loop control\t","afterContext":"markov decision processBellman equationforaging theory"},{"line":0,"link":"markov decision process","original":"[[markov decision process]]","displayText":"","beforeContext":"Neuromatchoptimal controloptimizationopen loop controlclosed loop control\tcomputational neuroscience","afterContext":"Bellman equationforaging theory"},{"line":0,"link":"Bellman equation","original":"[[Bellman equation]]","displayText":"","beforeContext":"Neuromatchoptimal controloptimizationopen loop controlclosed loop control\tcomputational neurosciencemarkov decision process","afterContext":"foraging theory"},{"line":0,"link":"foraging theory","original":"[[foraging theory]]","displayText":"","beforeContext":"Neuromatchoptimal controloptimizationopen loop controlclosed loop control\tcomputational neurosciencemarkov decision processBellman equation","afterContext":""},{"line":29,"link":"utility","original":"[[utility]]","displayText":"","beforeContext":"","afterContext":""},{"line":30,"link":"policy","original":"[[policy]]","displayText":"","beforeContext":"","afterContext":""},{"line":31,"link":"markov decision process","original":"[[markov decision process|markov decision process]]","displayText":"","beforeContext":"partially observable ","afterContext":" is an interactive hidden markov model"},{"line":31,"link":"hidden markov model","original":"[[hidden markov model]]","displayText":"","beforeContext":"partially observable markov decision process is an interactive ","afterContext":""}],"embeds":[{"line":13,"link":"optimal_control_cost.png","original":"![[optimal_control_cost.png]]","beforeContext":"","afterContext":""}],"tags":[],"headings":[{"line":10,"heading":"Optimal Control","level":1},{"line":25,"heading":"Takeaways","level":1},{"line":34,"heading":"Resources","level":1}]},"e9acad23d621e8a5c9b217a93edce151e2941e2d2cfe27fee59f19027b92bffa":{"links":[],"embeds":[],"tags":[],"headings":[]},"8329649b96a699f3170101c4ff58ceb6beabac0e85324818d4d4f015e8aec834":{"links":[],"embeds":[{"line":5,"link":"system_of_equations.png","original":"![[system_of_equations.png]]","beforeContext":"Example:","afterContext":""}],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":8,"heading":"Resources","level":1}]},"fe233b145d248f5317215a7e3d17494a706ccc39bc0520fd03c2018b666d2460":{"links":[{"line":0,"link":"linear algebra","original":"[[linear algebra]]","displayText":"","beforeContext":"","afterContext":"rank"},{"line":0,"link":"rank","original":"[[rank]]","displayText":"","beforeContext":"linear algebra","afterContext":""},{"line":15,"link":"rank","original":"[[rank|Rank]]","displayText":"Rank","beforeContext":"","afterContext":" refers to the number of dimensions in the output of a transformation"}],"embeds":[{"line":4,"link":"determinant 1.png","original":"![[determinant 1.png]]","beforeContext":"determinant refers to AREA","afterContext":""},{"line":18,"link":"determinant 1.png","original":"![[determinant 1.png]]","beforeContext":"Calculation:","afterContext":""}],"tags":[],"headings":[{"line":3,"heading":"Notes","level":1},{"line":21,"heading":"Resources","level":1}]},"ce7a339123509201024da7c32cdd9124903f15369b7466cfb1a26c4647cf70ba":{"links":[{"line":0,"link":"linear algebra","original":"[[linear algebra]]","displayText":"","beforeContext":"","afterContext":"determinantcolumn space"},{"line":0,"link":"determinant","original":"[[determinant]]","displayText":"","beforeContext":"linear algebra","afterContext":"column space"},{"line":0,"link":"column space","original":"[[column space]]","displayText":"","beforeContext":"linear algebradeterminant","afterContext":""},{"line":6,"link":"null space","original":"[[null space]]","displayText":"","beforeContext":"Set of vectors that land on the origin is called ","afterContext":""}],"embeds":[],"tags":[],"headings":[{"line":4,"heading":"Notes","level":1},{"line":8,"heading":"Resources","level":1}]},"768d06558f989ec68226a338c9c6c5999554ddb4635139f27a0375907d6c9803":{"links":[],"embeds":[],"tags":[],"headings":[]},"c1000aa9c00d2ed006ee3d59b71b676892014d4b3a93980d8b0b37dfb14ab0bc":{"links":[],"embeds":[],"tags":[],"headings":[]},"49bb47863a9707940370e780132bd389f4809402777329214c87ff9d0349bb7c":{"links":[{"line":0,"link":"reinforcement learning","original":"[[reinforcement learning]]","displayText":"","beforeContext":"","afterContext":"rewardneurosciencebounded rationalitypsychologymarkov decision processBellman equationtemporal difference learningdynamic programmingactor-criticdopaminepopulation codesdelay discountingmeta reinforcement learning"},{"line":0,"link":"reward","original":"[[reward]]","displayText":"","beforeContext":"reinforcement learning","afterContext":"neurosciencebounded rationalitypsychologymarkov decision processBellman equationtemporal difference learningdynamic programmingactor-criticdopaminepopulation codesdelay discountingmeta reinforcement learning"},{"line":0,"link":"neuroscience","original":"[[neuroscience]]","displayText":"","beforeContext":"reinforcement learningreward","afterContext":"bounded rationalitypsychologymarkov decision processBellman equationtemporal difference learningdynamic programmingactor-criticdopaminepopulation codesdelay discountingmeta reinforcement learning"},{"line":0,"link":"bounded rationality","original":"[[bounded rationality]]","displayText":"","beforeContext":"reinforcement learningrewardneuroscience","afterContext":"psychologymarkov decision processBellman equationtemporal difference learningdynamic programmingactor-criticdopaminepopulation codesdelay discountingmeta reinforcement learning"},{"line":0,"link":"psychology","original":"[[psychology]]","displayText":"","beforeContext":"reinforcement learningrewardneurosciencebounded rationality","afterContext":"markov decision processBellman equationtemporal difference learningdynamic programmingactor-criticdopaminepopulation codesdelay discountingmeta reinforcement learning"},{"line":0,"link":"markov decision process","original":"[[markov decision process]]","displayText":"","beforeContext":"reinforcement learningrewardneurosciencebounded rationalitypsychology","afterContext":"Bellman equationtemporal difference learningdynamic programmingactor-criticdopaminepopulation codesdelay discountingmeta reinforcement learning"},{"line":0,"link":"Bellman equation","original":"[[Bellman equation]]","displayText":"","beforeContext":"reinforcement learningrewardneurosciencebounded rationalitypsychologymarkov decision process","afterContext":"temporal difference learningdynamic programmingactor-criticdopaminepopulation codesdelay discountingmeta reinforcement learning"},{"line":0,"link":"temporal difference learning","original":"[[temporal difference learning]]","displayText":"","beforeContext":"reinforcement learningrewardneurosciencebounded rationalitypsychologymarkov decision processBellman equation","afterContext":"dynamic programmingactor-criticdopaminepopulation codesdelay discountingmeta reinforcement learning"},{"line":0,"link":"dynamic programming","original":"[[dynamic programming]]","displayText":"","beforeContext":"reinforcement learningrewardneurosciencebounded rationalitypsychologymarkov decision processBellman equationtemporal difference learning","afterContext":"actor-criticdopaminepopulation codesdelay discountingmeta reinforcement learning"},{"line":0,"link":"actor-critic","original":"[[actor-critic]]","displayText":"","beforeContext":"reinforcement learningrewardneurosciencebounded rationalitypsychologymarkov decision processBellman equationtemporal difference learningdynamic programming","afterContext":"dopaminepopulation codesdelay discountingmeta reinforcement learning"},{"line":0,"link":"dopamine","original":"[[dopamine]]","displayText":"","beforeContext":"reinforcement learningrewardneurosciencebounded rationalitypsychologymarkov decision processBellman equationtemporal difference learningdynamic programmingactor-critic","afterContext":"population codesdelay discountingmeta reinforcement learning"},{"line":0,"link":"population codes","original":"[[population codes]]","displayText":"","beforeContext":"reinforcement learningrewardneurosciencebounded rationalitypsychologymarkov decision processBellman equationtemporal difference learningdynamic programmingactor-criticdopamine","afterContext":"delay discountingmeta reinforcement learning"},{"line":0,"link":"delay discounting","original":"[[delay discounting]]","displayText":"","beforeContext":"reinforcement learningrewardneurosciencebounded rationalitypsychologymarkov decision processBellman equationtemporal difference learningdynamic programmingactor-criticdopaminepopulation codes","afterContext":"meta reinforcement learning"},{"line":0,"link":"meta reinforcement learning","original":"[[meta reinforcement learning]]","displayText":"","beforeContext":"reinforcement learningrewardneurosciencebounded rationalitypsychologymarkov decision processBellman equationtemporal difference learningdynamic programmingactor-criticdopaminepopulation codesdelay discounting","afterContext":""},{"line":17,"link":"policy","original":"[[policy]]","displayText":"","beforeContext":"Method to determine actions for agent (","afterContext":")"},{"line":21,"link":"greedy policy","original":"[[greedy policy|Greedy policy]]","displayText":"Greedy policy","beforeContext":"","afterContext":":"},{"line":24,"link":"delay discounting","original":"[[delay discounting]]","displayText":"","beforeContext":"defines an agents ","afterContext":" style"},{"line":29,"link":"dopamine","original":"[[dopamine|Dopamine]]","displayText":"Dopamine","beforeContext":"","afterContext":"\tand classical conditioning"},{"line":29,"link":"classical conditioning","original":"[[classical conditioning]]","displayText":"","beforeContext":"Dopamine\tand ","afterContext":""},{"line":36,"link":"model-free","original":"[[model-free]]","displayText":"","beforeContext":"still not clear on difference between ","afterContext":" and model-based"},{"line":36,"link":"model-based","original":"[[model-based]]","displayText":"","beforeContext":"still not clear on difference between model-free and ","afterContext":""}],"embeds":[{"line":26,"link":"agent_environment_interface.png","original":"![[agent_environment_interface.png]]","beforeContext":"Agent-Environment interface","afterContext":""},{"line":29,"link":"dopamine_classical_conditioning.png","original":"![[dopamine_classical_conditioning.png]]","beforeContext":"Dopamine\tand classical conditioning","afterContext":""}],"tags":[],"headings":[{"line":15,"heading":"Reinforcement Learning","level":1},{"line":35,"heading":"Takeaways","level":1},{"line":38,"heading":"Resources","level":1}]},"48788a59227a87a1187aee01b342659ee0a61393b8f1f8d94eb5d6129bba7918":{"links":[{"line":0,"link":"vectors","original":"[[vectors]]","displayText":"","beforeContext":"","afterContext":"basis vectorslinear system of equationsdot product"},{"line":0,"link":"basis vectors","original":"[[basis vectors]]","displayText":"","beforeContext":"vectors","afterContext":"linear system of equationsdot product"},{"line":0,"link":"linear system of equations","original":"[[linear system of equations]]","displayText":"","beforeContext":"vectorsbasis vectors","afterContext":"dot product"},{"line":0,"link":"dot product","original":"[[dot product]]","displayText":"","beforeContext":"vectorsbasis vectorslinear system of equations","afterContext":""},{"line":9,"link":"span","original":"[[span|Span]]","displayText":"Span","beforeContext":"","afterContext":": All the points in space the vector(s) can “reach”"},{"line":10,"link":"linear transformation","original":"[[linear transformation|Linear transformation]]","displayText":"Linear transformation","beforeContext":"","afterContext":": lines remain parallel (no curving) + origin remains fixed in place"},{"line":19,"link":"determinant","original":"[[determinant]]","displayText":"","beforeContext":"","afterContext":" of a transformation refers to the change in area of a region"},{"line":21,"link":"determinant","original":"[[determinant]]","displayText":"","beforeContext":"Example of a transformation and the ","afterContext":""},{"line":27,"link":"Strang_G","original":"[[Strang_G]]","displayText":"","beforeContext":"Book: /Users/djw/Documents/pCloud_synced/Academics/Books/Introduction to Linear Algebra, 4th edition--Gilbert Strang.pdf ","afterContext":""}],"embeds":[{"line":16,"link":"composition_matrix.png","original":"![[composition_matrix.png]]","beforeContext":"composition matrix can combine operations:","afterContext":""},{"line":21,"link":"determinant 1.png","original":"![[determinant 1.png]]","beforeContext":"Example of a transformation and the determinant","afterContext":""}],"tags":[],"headings":[{"line":5,"heading":"Notes","level":1},{"line":25,"heading":"Resources","level":1}]}},"algorithmVersion":9}