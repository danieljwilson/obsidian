[[modeling]]
[[model fitting]]
[[dimensionality reduction]]
[[principal component analysis]]
[[factor analysis]]
[[linear discriminant analysis]]
[[blind source separation]]
[[independent components analysis]]
[[intrinsic manifold]]

#neuromatch

# Dimensionality Reduction

**Rationale**: 
- Because neurons from networks, each neuron cannot act independently
- The brain has fewer degrees of freedom at its disposal than the number of neurons at play [[questions]]
 
**Reasons to Use**:
1. Single-trial analyses of neural population activity
2. Hypotheses about neural population activity structure
3. Exploratory analyses of large datasets

**Unsupervised methods**:
- Latent dynamical systems (LDS, LFADS) [[questions]]
- Non-linear methods (Isomap, LLE, t-SNE)

**Supervised Methods**:
- Linear Discriminant Analysis, dPCA

**[[independent components analysis|ICA]]**
-  requires statistical independence of components, not that they are uncorrelated like [[principal component analysis|PCA]] (stronger condition)
	- Can be use for [[blind source separation]]



# Take Aways
- Simplest method: [[principal component analysis]]
- Was originally seen mainly as a technique for visualizing data
- two vectors are orthonormal if: 
	1.   They are orthogonal (i.e., their dot product is zero):
	\begin{equation}
	{\bf u\cdot w} = u_1 w_1 + u_2 w_2 = 0
	\end{equation}
	2.   They have unit length:
	\begin{equation}
	||{\bf u} || = ||{\bf w} || = 1
	\end{equation}
	
	

# Resources
- [Youtube playlist](https://www.youtube.com/watch?v=zeBFyRaoVnQ&list=PLkBQOLLbi18N0E0Bx-ZueacF2oRr5eEpU)
- [Notebooks](https://github.com/NeuromatchAcademy/course-content/blob/master/tutorials/README.md)
- DataHigh Software