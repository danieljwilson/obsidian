


# Notes
Entropy used as a measure to show that the [[Exponential distribution|exponential distribution]] can contain more information (with the same number of neuron spikes) than a [[Uniform distribution|uniform distribution]], which is generally seen as the limit of a distribution's information. 

**Question**: How then can the exponential contain more information? Because it it taking into account the physiological constraints of the brain, in this case the number of neuron spikes. However, as I think about this more I am less certain - as it seems like one neuron spike for each timepoint would clearly be the highest possible information. Again the biological constraint in this case may be time.

**[[Ideas|Idea]]**: Check the shape of the distribution of letters in the English language. And perhaps also bi-grams.

# Resources
Neuromatch notebook dealing with [[Entropy|entropy]] and the brain