# Info
**Title**: Why humans are (sometimes) less rational than other animals: Cognitive complexity and the axioms of rational choice
**Journal**: Thinking and Reasoning
**Year**: 2013
**Authors**: [[Keith E. Stanovich]]

**Link**: [paperpile](chrome-extension://bomfdkbfpdhijjbeoicnfhjbdhncfhig/view.html?mp=fEOWRlwZ)
**Tags**: #paper
**Rating**: #4star

**Connections**:
[[axioms of rational choice]]
[[decision making]]
[[context]]
[[utility theory]]

# Notes
## Summary
Formal analyses in [[decision theory]] show that you maximize [[utility]] if you follow the [[axioms of rational choice]].

**However**, humans often violate the [[axioms of rational choice]]...

**Also**, interestingly, non-human animals can display **more rational** behavior in this axiomatic utility maximizing sense.

[[Keith E. Stanovich]] gives three reasons for this apparent paradox:

**1. Contextual Complexity**
- humans process more (and more complex) contextual information than animals
- principles of [[rational choice]] are, in fact, **easier** to follow when the cognitive architecture of the organism is simpler
- [[axioms of rational choice]] ignore [[context effects]]/[[decision environment]]
- contextual features humans code into options may lack stability both for good reasons (the social world is not stable) and bad reasons (the cues are too many and varying to be coded consistently each time, i.e. [[noise]]).

**2. Symbolic Complexity**
- humans can make both [[instrumental rationality|instrumentally rational]] choices and [[expressive rationality|expressively rational]] choices. 
- Idea that some choices are made to reinforce our [[self-image]]

**3. The Strong Evaluator Struggle**
- perhaps better thought of as [[second-order preference]]

Idea that freedom from constraints afforded by abundance of our current world allow us to pursue [[symbolic utility]] which complicates [[preference]] and often leads to violations of [[instrumental rationality]].

>We are the only species that disrupts the coherence of its preferences by destabilising them through cognition directed at self-improvement and self-determination

- means we can feel strangely alienated from our own choices...i.e. upset with ourselves for choosing to do/not do something...

## Thoughts
- this seems really just a basic problem of [[decision environment]], no?
- if you put non-human animals in very artificial settings could you not get them to make non-utility maximizing choices? *e.g. the rat who starved to death while stimulating the pleasure center's of its brain*
- I think that the conflict/gap between [[first-order preference]] and [[second-order preference]] is getting close to the gap that I am interested in investigating.

# Resources
